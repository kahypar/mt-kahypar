{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff526d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import benchmark_visualization as bv\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from statistics import geometric_mean\n",
    "\n",
    "HOME_DIR = os.environ['HOME']\n",
    "\n",
    "SHORT_TIMELIMIT = 7200\n",
    "LONG_TIMELIMIT = 28800\n",
    "\n",
    "runs = {}\n",
    "class BenchmarkRun:\n",
    "    HEADER = \"algorithm,graph,timeout,seed,k,epsilon,num_threads,imbalance,totalPartitionTime,objective,km1,cut,failed\"\n",
    "    \n",
    "    def __init__(self, content: str, timelimit: int = None):\n",
    "        self.data = {}\n",
    "        for i, key in enumerate(self.HEADER.split(',')):\n",
    "            value = content.split(',')[i].strip()\n",
    "            # Try to convert to int or float if possible\n",
    "            try:\n",
    "                if '.' in value:\n",
    "                    value = float(value)\n",
    "                else:\n",
    "                    value = int(value)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            self.data[key] = value\n",
    "        self.data['timelimit'] = timelimit\n",
    "\n",
    "    def get(self, param):\n",
    "        return self.data[param]\n",
    "\n",
    "def parse_results_file(file_path: str):\n",
    "    results_array = []\n",
    "    timelimit = file_path.split('.')[-2]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            results_array += [BenchmarkRun(content=line, timelimit=int(timelimit))]\n",
    "    return results_array\n",
    "\n",
    "def aggregate_runs(directory_path: str, instances_to_exclude: list = []):\n",
    "    runs = {}\n",
    "    for file_path in glob.glob(directory_path + \"/*.results\"):\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        instance_name = '.'.join(file_name.split('.')[:-2])\n",
    "        purely_instance_name = '.'.join(instance_name.split('.')[:-3])\n",
    "        if purely_instance_name in instances_to_exclude:\n",
    "            continue   \n",
    "        if instance_name not in runs:\n",
    "            runs[instance_name] = {\"short\": None, \"long\": None}\n",
    "\n",
    "        run_results = parse_results_file(file_path)\n",
    "        if len(run_results) > 1:\n",
    "            min_km1=min([run.get('km1') for run in run_results if run.get('failed') == 'no'])\n",
    "            runs[instance_name][\"short\"] = min_km1\n",
    "        elif run_results:\n",
    "            runs[instance_name][\"long\"] = run_results[0].get('km1')\n",
    "        else:\n",
    "            pass\n",
    "            #print(f\"Warning: No results in file {file_path}\")\n",
    "\n",
    "    return runs\n",
    "\n",
    "\n",
    "\n",
    "def convert_instance_naming_scheme(instance_name: str, use_fixed_seed: bool) -> str:\n",
    "    parts = instance_name.split('.')\n",
    "    hgr_index = parts.index('hgr')\n",
    "    base_name = '.'.join(parts[:hgr_index + 1])\n",
    "    \n",
    "    # Extract parameters from the rest\n",
    "    k_value = None\n",
    "    seed_value = None\n",
    "    timelimit_value = None\n",
    "\n",
    "    for part in parts[hgr_index + 1:]:\n",
    "        if part.startswith('k'):\n",
    "            k_value = part[1:]\n",
    "        elif part.startswith('seed'):\n",
    "            seed_value = part[4:]\n",
    "        elif part.startswith('timelimit'):\n",
    "            timelimit_value = part[9:]\n",
    "    \n",
    "    # Construct new name: base.threads.k.seed.timelimit\n",
    "    threads = '1'  # Default to 1 thread if not specified\n",
    "    if use_fixed_seed:\n",
    "        seed_value = '1'\n",
    "    new_name = f\"{base_name}.{threads}.{k_value}.{seed_value}.{timelimit_value}\"\n",
    "    return new_name\n",
    "\n",
    "\n",
    "def parse_end_result_history_file(file_path: str):\n",
    "    # Read the last number from the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if lines:\n",
    "            last_line = lines[-1].strip()\n",
    "            km1 = int(last_line.split(',')[-1].strip())\n",
    "        else:\n",
    "            km1 = None\n",
    "    return km1\n",
    "\n",
    "def parse_history_file(file_path: str):\n",
    "    history = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue         \n",
    "            if line.startswith('Starttime:'):\n",
    "                timestamp = int(line.split(':')[1].strip())\n",
    "                history.append((timestamp, None, None))\n",
    "            else:\n",
    "                parts = line.split(',')\n",
    "                timestamp = int(parts[0].strip())\n",
    "                mode = parts[1].strip()\n",
    "                km1_value = int(parts[2].strip())\n",
    "                history.append((timestamp, mode, km1_value)) \n",
    "    return history\n",
    "\n",
    "def get_average_diff_from_matrix(matrix):\n",
    "    np_matrix = np.array(matrix)\n",
    "    mask = ~np.eye(np_matrix.shape[0], dtype=bool)\n",
    "    off = np_matrix[mask]\n",
    "    mean = (off.mean() if off.size else 0)\n",
    "    return mean\n",
    "\n",
    "def get_average_diff_from_matrices(matrices):\n",
    "    averages = []\n",
    "    for matrix in matrices:\n",
    "        avg = get_average_diff_from_matrix(matrix)\n",
    "        averages.append(avg)\n",
    "    return averages\n",
    "\n",
    "def get_max_diff_from_matrix(matrix):\n",
    "    np_matrix = np.array(matrix)\n",
    "    max_val = np_matrix.max()\n",
    "    return max_val\n",
    "\n",
    "def get_max_diff_from_matrices(matrices):\n",
    "    max_values = []\n",
    "    for matrix in matrices:\n",
    "        max_val = get_max_diff_from_matrix(matrix)\n",
    "        max_values.append(max_val)\n",
    "    return max_values\n",
    "\n",
    "def plot_combined_data(combined_data, title: str = \"Combined History and Difference Matrices\"):\n",
    "    timestamps = [entry['timestamp'] for entry in combined_data]\n",
    "    km1_values = [entry['km1'] for entry in combined_data]\n",
    "    avg_diffs = [get_average_diff_from_matrix(entry['diff_matrix']) for entry in combined_data]\n",
    "    max_diffs = [get_max_diff_from_matrix(entry['diff_matrix']) for entry in combined_data]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # First subplot: KM1 values\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax1.set_ylabel('KM1 Value', color=color, fontsize=12)\n",
    "    ax1.plot(timestamps, km1_values, color=color, marker='o', label='KM1 Value')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.set_title('KM1 Value over Time', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Second subplot: Average and Max Differences\n",
    "    ax2.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax2.set_ylabel('Difference Value', fontsize=12)\n",
    "    ax2.plot(timestamps, avg_diffs, color='tab:red', marker='x', label='Average Difference')\n",
    "    ax2.plot(timestamps, max_diffs, color='tab:orange', marker='s', label='Max Difference')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_title('Difference Metrics over Time', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def combine_history_and_diff(history_run, diff_run):\n",
    "    combined_data = []\n",
    "    index = 0\n",
    "    start_time = None\n",
    "    \n",
    "    for step in history_run:\n",
    "        timestamp, mode, km1_value = step\n",
    "        if mode == None:\n",
    "            start_time = timestamp\n",
    "            continue\n",
    "        if mode == 'Initial':\n",
    "            # skip\n",
    "            continue\n",
    "        \n",
    "        relative_time = (timestamp - start_time) / 1000.0  \n",
    "        \n",
    "        combined_data.append({\n",
    "            'timestamp': relative_time,\n",
    "            'mode': mode,\n",
    "            'km1': km1_value,\n",
    "            'diff_matrix': diff_run[index]\n",
    "        })\n",
    "        index += 1\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "def aggregate_history_runs(directory_path: str, full_history: bool = False, instances_to_exclude: list = []):\n",
    "    history_runs = {}\n",
    "    for file_path in glob.glob(directory_path + \"/*.csv\"):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        thread_id = file_name.split('.')[-3]\n",
    "        instance_name = '.'.join(file_name.split('.')[:-3]) \n",
    "        \n",
    "        use_fixed_seed = True\n",
    "        if full_history:\n",
    "            use_fixed_seed = False\n",
    "        instance_name = convert_instance_naming_scheme(instance_name, use_fixed_seed)\n",
    "        \n",
    "        purely_instance_name = '.'.join(instance_name.split('.')[:-4])\n",
    "        if purely_instance_name in instances_to_exclude:\n",
    "            continue\n",
    "        \n",
    "        history = parse_history_file(file_path)\n",
    "        \n",
    "        # Last entry should be the final result\n",
    "        km1 = None\n",
    "        for timestamp, mode, km1_value in reversed(history):\n",
    "            if mode is not None:\n",
    "                km1 = km1_value\n",
    "                break\n",
    "\n",
    "        # Store only the history for the best run\n",
    "        if instance_name not in history_runs:\n",
    "            history_runs[instance_name] = {'thread_id': thread_id, 'km1': km1, 'history': history}\n",
    "        else:\n",
    "            if history_runs[instance_name]['km1'] is None:\n",
    "                pass\n",
    "            if km1 is not None and km1 < history_runs[instance_name]['km1']:\n",
    "                history_runs[instance_name] = {'thread_id': thread_id, 'km1': km1, 'history': history}\n",
    "\n",
    "    return history_runs\n",
    "\n",
    "def get_diff_matrices_for_best_run(history_runs, diff_matrices_list, instance_name: str):\n",
    "    if instance_name not in history_runs:\n",
    "        return None\n",
    "\n",
    "    best_thread_id = history_runs[instance_name]['thread_id']\n",
    "    for entry in diff_matrices_list:\n",
    "        if entry['thread_id'] == best_thread_id:\n",
    "            return entry['matrices']\n",
    "    return None\n",
    "\n",
    "\n",
    "def aggregate_diff_runs(directory_path: str, instances_to_exclude: list = []):\n",
    "    diff_runs = {}\n",
    "    for file_path in glob.glob(directory_path + \"/*.csv\"):\n",
    "        matrices = bv.parse_diff_matrices(file_path)\n",
    "        file_name = os.path.basename(file_path)\n",
    "        thread_id = file_name.split('.')[-3]\n",
    "        instance_name = '.'.join(file_name.split('.')[:-3])\n",
    "        use_fixed_seed = True\n",
    "        instance_name = convert_instance_naming_scheme(instance_name, use_fixed_seed)\n",
    "        purely_instance_name = '.'.join(instance_name.split('.')[:-4])\n",
    "        if purely_instance_name in instances_to_exclude:\n",
    "            continue\n",
    "        if instance_name not in diff_runs:\n",
    "            diff_runs[instance_name] = []    \n",
    "        diff_runs[instance_name].append({\n",
    "            'thread_id': thread_id,\n",
    "            'matrices': matrices\n",
    "        })\n",
    "\n",
    "    return diff_runs\n",
    "\n",
    "def split_long_short_history_runs(history_runs):\n",
    "    long_runs = {}\n",
    "    short_runs = {}\n",
    "    for instance_name, run_data in history_runs.items():\n",
    "        timelimit = int(instance_name.split('.')[-1])\n",
    "        if timelimit == SHORT_TIMELIMIT:\n",
    "            short_runs[instance_name] = run_data\n",
    "        else:\n",
    "            long_runs[instance_name] = run_data\n",
    "    return short_runs, long_runs\n",
    "\n",
    "def split_seed_history_runs(history_runs):\n",
    "    seed_runs = {}\n",
    "    for instance_name, run_data in history_runs.items():\n",
    "        seed = instance_name.split('.')[-2]\n",
    "        if seed not in seed_runs:\n",
    "            seed_runs[seed] = {}\n",
    "        seed_runs[seed][instance_name] = run_data\n",
    "        \n",
    "    ## Convert to list\n",
    "    seed_count = seed_runs.keys().__len__()\n",
    "    all_seeds_runs = [None] * seed_count\n",
    "    for seed, runs in seed_runs.items():\n",
    "        seed_int= int(seed)\n",
    "        all_seeds_runs[seed_int - 1] = runs\n",
    "    return all_seeds_runs\n",
    "\n",
    "\n",
    "def split_k_value_history_runs(history_runs, *k_values):\n",
    "    k_runs_list = [{} for _ in k_values]\n",
    "    k_value_to_index = {k: i for i, k in enumerate(k_values)}\n",
    "\n",
    "    for instance_name, run_data in history_runs.items():\n",
    "        k_from_instance = instance_name.split('.')[-3]\n",
    "        \n",
    "        if k_from_instance in k_value_to_index:\n",
    "            index = k_value_to_index[k_from_instance]\n",
    "            k_runs_list[index][instance_name] = run_data\n",
    "            \n",
    "    return k_runs_list\n",
    "\n",
    "def convert_time_for_history_run(history_run):   \n",
    "    converted_history = []\n",
    "    start_time = None\n",
    "    for timestamp, mode, km1_value in history_run:\n",
    "        if mode is None:\n",
    "            start_time = timestamp\n",
    "            # check if already converted first\n",
    "            if start_time == 0:\n",
    "                return history_run.copy()\n",
    "            converted_history.append((0, mode, km1_value))\n",
    "        else:\n",
    "            relative_time = (timestamp - start_time) / 1000.0  \n",
    "            converted_history.append((relative_time, mode, km1_value))\n",
    "    return converted_history\n",
    "\n",
    "\n",
    "def make_history_runs_sequential(*history_runs, time_limit=None):\n",
    "    combined_runs = {}\n",
    "    padded_history_runs = [None] * len(history_runs)\n",
    "    # Add time_limit to history run timestamps\n",
    "    for i, history_run in enumerate(history_runs):\n",
    "        padded_history_run = {}\n",
    "        for instance_name, run_data in history_run.items():\n",
    "            # Fix seed to 1 for combined run\n",
    "            instance_name_converted = instance_name.rsplit('.', 2)[0] + '.1.' + instance_name.rsplit('.', 1)[1]\n",
    "            \n",
    "            # Create a COPY of the history to avoid modifying original\n",
    "            history = [entry for entry in run_data['history']]  # Copy list\n",
    "            converted_history = convert_time_for_history_run(history)\n",
    "            \n",
    "            # Create new history with offset times\n",
    "            new_history = []\n",
    "            for timestamp, mode, km1_value in converted_history:\n",
    "                new_history.append((timestamp + i * time_limit, mode, km1_value))\n",
    "            \n",
    "            padded_history_run[instance_name_converted] = {\n",
    "                'thread_id': run_data['thread_id'], \n",
    "                'km1': run_data['km1'], \n",
    "                'history': new_history\n",
    "            }\n",
    "        padded_history_runs[i] = padded_history_run\n",
    "    # Combine all padded history runs\n",
    "    combined_runs = merge_histories(*padded_history_runs)\n",
    "    return combined_runs\n",
    "\n",
    "def merge_histories(*history_runs):\n",
    "    merged_histories = {}\n",
    "    for history_run in history_runs:\n",
    "        for instance_name, run_data in history_run.items():\n",
    "            if instance_name not in merged_histories:\n",
    "                # Deep copy the run_data\n",
    "                merged_histories[instance_name] = {\n",
    "                    'thread_id': run_data['thread_id'],\n",
    "                    'km1': run_data['km1'],\n",
    "                    'history': [entry for entry in run_data['history']]  # Copy history\n",
    "                }\n",
    "            else:\n",
    "                existing_history = merged_histories[instance_name]['history']\n",
    "                new_history = run_data['history']\n",
    "                # Append new history entries (creates new list)\n",
    "                merged_histories[instance_name]['history'] = existing_history + [entry for entry in new_history]\n",
    "                # Update km1 and thread_id if new run is better\n",
    "                if run_data['km1'] < merged_histories[instance_name]['km1']:\n",
    "                    merged_histories[instance_name]['km1'] = run_data['km1']\n",
    "                    merged_histories[instance_name]['thread_id'] = run_data['thread_id']\n",
    "                \n",
    "    # Sort histories by timestamp\n",
    "    for instance_name, run_data in merged_histories.items():\n",
    "        run_data['history'].sort(key=lambda x: x[0])\n",
    "    # History for each instance shall only contain decreasing km1 values\n",
    "    for instance_name, run_data in merged_histories.items():\n",
    "        filtered_history = []\n",
    "        last_km1 = float('inf')\n",
    "        for entry in run_data['history']:\n",
    "            time, mode, km1_value = entry\n",
    "            if km1_value is not None and km1_value < last_km1:\n",
    "                filtered_history.append(entry)\n",
    "                last_km1 = km1_value\n",
    "            elif time == 0:\n",
    "                filtered_history.append((0, None, None))\n",
    "        run_data['history'] = filtered_history\n",
    "    return merged_histories\n",
    "\n",
    "def split_runs_k_value(runs, *k_values):\n",
    "# Create a list of empty dictionaries, one for each k-value\n",
    "    k_runs_list = [{} for _ in k_values]\n",
    "    \n",
    "    # Create a mapping from k_value to its index for quick lookups\n",
    "    k_value_to_index = {k: i for i, k in enumerate(k_values)}\n",
    "\n",
    "    for instance_name, run_data in runs.items():\n",
    "        k_from_instance = instance_name.split('.')[-2]\n",
    "        \n",
    "        if k_from_instance in k_value_to_index:\n",
    "            index = k_value_to_index[k_from_instance]\n",
    "            k_runs_list[index][instance_name] = run_data\n",
    "                \n",
    "    return k_runs_list\n",
    "\n",
    "def extract_info_from_config(config_name: str):\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    different_param_separator = \"-\"\n",
    "    same_param_separator = \"_\"\n",
    "    parts = config_name.split(different_param_separator)\n",
    "    # skip date format \n",
    "    parts = parts[2:]\n",
    "    parts[0] = parts[0][1:]\n",
    "    # delete first _\n",
    "    parts = [part[1:] if part.startswith('_') else part for part in parts]\n",
    "    # Further split each part by the same_param_separator\n",
    "    for p in parts :\n",
    "        # Split by same_param_separator\n",
    "        subparts = p.split(same_param_separator)\n",
    "        # first subpart is parameter\n",
    "        param_name = subparts[0]\n",
    "        # rest are values\n",
    "        param_values = subparts[1:]\n",
    "        result_dict[param_name] = param_values\n",
    "    return result_dict\n",
    "\n",
    "def create_geomean_over_all_instances(history_runs):\n",
    "    result_list = []\n",
    "    current_indices = {}\n",
    "    current_values = {}\n",
    "    current_times = {}\n",
    "    max_time = 0\n",
    "    \n",
    "    converted_runs = {}\n",
    "    for instance_name, run_data in history_runs.items():\n",
    "        converted_history = convert_time_for_history_run(run_data['history'])\n",
    "        converted_runs[instance_name] = converted_history\n",
    "\n",
    "    # First value is special case\n",
    "    for i, (instance_name, history) in enumerate(converted_runs.items()):\n",
    "        time, mode, km1_value = history[1]\n",
    "        current_values[instance_name] = km1_value\n",
    "        current_indices[instance_name] = 1\n",
    "        current_times[instance_name] = time\n",
    "        if time > max_time:\n",
    "            max_time = time\n",
    "    \n",
    "    # update other instances to match max_time\n",
    "    for instance_name in current_times:\n",
    "        while current_times[instance_name] < max_time:\n",
    "            index = current_indices[instance_name]\n",
    "            history = converted_runs[instance_name]\n",
    "            if index + 1 < len(history) and history[index + 1][0] <= max_time:\n",
    "                time, mode, km1_value = history[index + 1]\n",
    "                current_indices[instance_name] += 1\n",
    "                current_values[instance_name] = km1_value\n",
    "                current_times[instance_name] = time\n",
    "            else:\n",
    "                break\n",
    "    # Check for 0 values in current_results and substitute with 1\n",
    "    for instance_name in current_values:\n",
    "        if current_values[instance_name] == 0:\n",
    "            current_values[instance_name] = 1 \n",
    "    result_list.append((max_time, geometric_mean(current_values.values())))\n",
    "    \n",
    "    end = False\n",
    "    while not end:\n",
    "        next_time = float('inf')\n",
    "        for i, (instance_name, history) in enumerate(converted_runs.items()):\n",
    "            index = current_indices[instance_name]\n",
    "            if index + 1 < len(history):\n",
    "                time, mode, km1_value = history[index + 1]\n",
    "                if time < next_time:\n",
    "                    next_time = time\n",
    "                    instance_to_increment = instance_name\n",
    "                    km1_to_update = km1_value\n",
    "        ## next time found\n",
    "        if next_time == float('inf'):\n",
    "            end = True\n",
    "            continue\n",
    "        # Increment the current index for the instance with the next time\n",
    "        current_indices[instance_to_increment] += 1\n",
    "        current_values[instance_to_increment] = km1_to_update\n",
    "        current_times[instance_to_increment] = next_time\n",
    "        \n",
    "        # append result list\n",
    "        result_list.append((next_time, geometric_mean(current_values.values())))\n",
    "\n",
    "    return result_list\n",
    "\n",
    "def plot_time_series(*datasets, title: str = \"Geometric Mean KM1 over Time\", labels=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    colors = ['b', 'r', 'g', 'orange', 'purple', 'brown', 'pink', 'gray', 'cyan']\n",
    "    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*']\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = [f'Dataset {i+1}' for i in range(len(datasets))]\n",
    "    \n",
    "    for i, data in enumerate(datasets):\n",
    "        times = [entry[0] for entry in data]\n",
    "        geomeans = [entry[1] for entry in data]\n",
    "        \n",
    "        color = colors[i % len(colors)]\n",
    "        marker = markers[i % len(markers)]\n",
    "        label = labels[i] if i < len(labels) else f'Dataset {i+1}'\n",
    "        \n",
    "        plt.plot(times, geomeans, marker=marker, color=color, label=label, markersize=3)\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time (seconds)', fontsize=12)\n",
    "    plt.ylabel('Geometric Mean KM1', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_single_matrix(matrix, title: str = \"Difference Matrix\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        matrix = np.array(matrix)\n",
    "    \n",
    "    im = plt.imshow(matrix, cmap='viridis', aspect='auto', interpolation='nearest')\n",
    "    \n",
    "    plt.colorbar(im, label='Difference Value')\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    # plt.xlabel('Iteration', fontsize=12)\n",
    "    # plt.ylabel('Iteration', fontsize=12)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # Tight layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df045b47",
   "metadata": {},
   "source": [
    "### Various different results analysis ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d085d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_FILES_DIR = f\"{HOME_DIR}/Documents/experiment_results/2025-10-24_test_results/mt_kahypar_evo_results\"\n",
    "DIFF_FILES_DIR = f\"{HOME_DIR}/Documents/experiment_results/2025-10-24_test_results/evo_diff_results\"\n",
    "HISTORY_FILES_DIR = f\"{HOME_DIR}/Documents/experiment_results/2025-10-24_test_results/evo_results_results\"\n",
    "\n",
    "\n",
    "# Aggregate runs from result files\n",
    "runs = aggregate_runs(RESULT_FILES_DIR)\n",
    "k8_runs, k32_runs = split_runs_k_value(runs, '8', '32')\n",
    "\n",
    "diff_array_k2 = []\n",
    "for instance_name, results in k32_runs.items():\n",
    "    short_km1 = results[\"short\"]\n",
    "    long_km1 = results[\"long\"]\n",
    "    if short_km1 is not None and long_km1 is not None:\n",
    "        diff = long_km1 - short_km1\n",
    "        diff_array_k2.append(diff)\n",
    "diff_array_k8 = []\n",
    "for instance_name, results in k8_runs.items():\n",
    "    short_km1 = results[\"short\"]\n",
    "    long_km1 = results[\"long\"]\n",
    "    if short_km1 is not None and long_km1 is not None:\n",
    "        diff = long_km1 - short_km1\n",
    "        diff_array_k8.append(diff)\n",
    "\n",
    "# How often is long run better than short runs (percentage)\n",
    "if diff_array_k2:\n",
    "    better_count = sum(1 for d in diff_array_k2 if d < 0)\n",
    "    same_count = sum(1 for d in diff_array_k2 if d == 0)\n",
    "    percentage_better = (better_count / len(diff_array_k2)) * 100\n",
    "    percentage_same = (same_count / len(diff_array_k2)) * 100\n",
    "    print(f\"Percentage of instances where long run is better than short runs (k=32): {percentage_better:.2f}%\")\n",
    "    print(f\"Percentage of instances where long run is the same as short runs (k=32): {percentage_same:.2f}%\")\n",
    "    # better_count_k8 = sum(1 for d in diff_array_k8 if d < 0)\n",
    "    # percentage_better_k8 = (better_count_k8 / len(diff_array_k8)) * 100\n",
    "    # print(f\"Percentage of instances where long run is better than short runs (k=8): {percentage_better_k8:.2f}%\")\n",
    "else:\n",
    "    print(\"No valid differences to analyze.\")\n",
    "\n",
    "\n",
    "# Get Geomean for short and long runs\n",
    "short_km1_values_k32 = [km1[\"short\"] for km1 in k32_runs.values() if km1[\"short\"] is not None]\n",
    "long_km1_values_k32 = [km1[\"long\"] for km1 in k32_runs.values() if km1[\"long\"] is not None]\n",
    "if short_km1_values_k32 and long_km1_values_k32:\n",
    "    geomean_short = geometric_mean(short_km1_values_k32)\n",
    "    geomean_long = geometric_mean(long_km1_values_k32)\n",
    "    print(f\"Geometric Mean KM1 (k=32) - Short Runs: {geomean_short}, Long Runs: {geomean_long}\")\n",
    "    \n",
    "short_km1_values_k8 = [km1[\"short\"] for km1 in k8_runs.values() if km1[\"short\"] is not None]\n",
    "long_km1_values_k8 = [km1[\"long\"] for km1 in k8_runs.values() if km1[\"long\"] is not None]\n",
    "if short_km1_values_k8 and long_km1_values_k8:\n",
    "    geomean_short_k8 = geometric_mean(short_km1_values_k8)\n",
    "    geomean_long_k8 = geometric_mean(long_km1_values_k8)\n",
    "    print(f\"Geometric Mean KM1 (k=8) - Short Runs: {geomean_short_k8}, Long Runs: {geomean_long_k8}\")\n",
    "\n",
    "# Analyze largest relative differences (in favor of long runs)\n",
    "relative_diffs = []\n",
    "for run, km1 in k32_runs.items():\n",
    "    short_km1 = km1[\"short\"]\n",
    "    long_km1 = km1[\"long\"]\n",
    "    if short_km1 is not None and long_km1 is not None:\n",
    "        diff = long_km1 - short_km1\n",
    "        relative_diff = diff / short_km1\n",
    "        relative_diffs.append((run, relative_diff))\n",
    "relative_diffs.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"relative differences: \", relative_diffs[:10])\n",
    "\n",
    "\n",
    "# Diff Matrices Analysis\n",
    "diff_runs = aggregate_diff_runs(DIFF_FILES_DIR)\n",
    "\n",
    "# Analyze diff matrices for worst long runs\n",
    "show_full_history = False\n",
    "\n",
    "history_runs = aggregate_history_runs(HISTORY_FILES_DIR, full_history=show_full_history)\n",
    "for run, _ in relative_diffs[:10]:\n",
    "    short_instance = f\"{run}.{SHORT_TIMELIMIT}\"\n",
    "    long_instance = f\"{run}.{LONG_TIMELIMIT}\"   \n",
    "    if short_instance in diff_runs and long_instance in diff_runs:\n",
    "        \n",
    "        short_matrices = diff_runs[short_instance]\n",
    "        long_matrices = diff_runs[long_instance]\n",
    "\n",
    "        if len(long_matrices[0]['matrices']) == 0:\n",
    "            continue\n",
    "        if len(short_matrices[0]['matrices']) == 0:\n",
    "            continue\n",
    "\n",
    "        best_short_matrices = get_diff_matrices_for_best_run(history_runs, short_matrices, short_instance)\n",
    "        last_short_matrix = best_short_matrices[-1] if best_short_matrices else None\n",
    "        last_long_matrix = long_matrices[0]['matrices'][-1]\n",
    "        \n",
    "        long_diff_run = long_matrices[0]['matrices']\n",
    "        short_diff_run = best_short_matrices\n",
    "        short_history_run = history_runs[short_instance]['history']\n",
    "        long_history_run = history_runs[long_instance]['history']\n",
    "        \n",
    "        combined_short = combine_history_and_diff(short_history_run, short_diff_run)\n",
    "        combined_long = combine_history_and_diff(long_history_run, long_diff_run)\n",
    "        plot_combined_data(combined_short, title=f\"Short Run Combined Data for {short_instance}\")\n",
    "        plot_combined_data(combined_long, title=f\"Long Run Combined Data for {long_instance}\")\n",
    "\n",
    "        if last_short_matrix and last_long_matrix:\n",
    "            plot_single_matrix(last_short_matrix, title=f\"Short Run Diff Matrix for {short_instance}\")\n",
    "            plot_single_matrix(last_long_matrix, title=f\"Long Run Diff Matrix for {long_instance}\")\n",
    "        \n",
    "# Geometric Mean over all instances\n",
    "short_history_runs, long_history_runs = split_long_short_history_runs(history_runs)\n",
    "short_k8_runs, short_k32_runs = split_k_value_history_runs(short_history_runs, '8', '32')\n",
    "long_k8_runs, long_k32_runs = split_k_value_history_runs(long_history_runs, '8', '32')\n",
    "geomean_short = create_geomean_over_all_instances(short_k32_runs)\n",
    "geomean_long = create_geomean_over_all_instances(long_k32_runs)\n",
    "plot_time_series(geomean_short, geomean_long, \n",
    "                 title=\"Geometric Mean KM1 over Time (Short vs Long Runs)\",\n",
    "                 labels=['Short Runs', 'Long Runs'])\n",
    "\n",
    "# Show full history\n",
    "show_full_history = True\n",
    "history_runs = aggregate_history_runs(HISTORY_FILES_DIR, full_history=show_full_history)\n",
    "short_history_runs_full, _ = split_long_short_history_runs(history_runs)\n",
    "_, short_k32_runs_full = split_k_value_history_runs(short_history_runs_full, '8', '32')\n",
    "all_seeds_short_histories_k32 = split_seed_history_runs(short_k32_runs_full)\n",
    "\n",
    "fixed_short_history_runs = make_history_runs_sequential(*all_seeds_short_histories_k32, time_limit=SHORT_TIMELIMIT)\n",
    "fixed_geomean_short = create_geomean_over_all_instances(fixed_short_history_runs)\n",
    "\n",
    "geomean_for_all_seeds = []\n",
    "for seed_runs in all_seeds_short_histories_k32:\n",
    "    geomean = create_geomean_over_all_instances(seed_runs)\n",
    "    geomean_for_all_seeds.append(geomean)\n",
    "plot_time_series(*geomean_for_all_seeds, fixed_geomean_short, geomean_long,\n",
    "                 title=\"Geometric Mean KM1 over Time (k=32)\",\n",
    "                 labels=[f'Seed {i+1}' for i in range(len(geomean_for_all_seeds))] + ['Combined best Short Runs', 'Long Runs'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae75b3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing configuration: 2025-11-8_kway_5-k_16_32\n",
      "Processing configuration: 2025-11-8_kway_2-k_4_8\n",
      "Processing configuration: 2025-11-8_kway_5-k_4_8\n",
      "Processing configuration: 2025-11-8_kway_2-k_16_32\n",
      "Processing configuration: 2025-11-8_kway_5-k_4_8\n",
      "Processing configuration: 2025-11-8_kway_2-k_16_32\n",
      "Processing configuration: 2025-11-8_kway_4-k_16_32\n",
      "Processing configuration: 2025-11-8_kway_4-k_16_32\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "geometric mean requires a non-empty dataset containing positive numbers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m k_run \u001b[38;5;241m=\u001b[39m k_runs_dict[k]\n\u001b[1;32m     49\u001b[0m k_history_run \u001b[38;5;241m=\u001b[39m k_history_runs_dict[k]\n\u001b[0;32m---> 50\u001b[0m geomean \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_geomean_over_all_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_history_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m config \u001b[38;5;241m=\u001b[39m (k, kway_value, pop_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m pop_size \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_POP_SIZE)\n\u001b[1;32m     52\u001b[0m all_geomeans[config] \u001b[38;5;241m=\u001b[39m geomean\n",
      "Cell \u001b[0;32mIn[1], line 474\u001b[0m, in \u001b[0;36mcreate_geomean_over_all_instances\u001b[0;34m(history_runs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_values[instance_name] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    473\u001b[0m         current_values[instance_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m--> 474\u001b[0m result_list\u001b[38;5;241m.\u001b[39mappend((max_time, \u001b[43mgeometric_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    476\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m end:\n",
      "File \u001b[0;32m/usr/lib/python3.12/statistics.py:541\u001b[0m, in \u001b[0;36mgeometric_mean\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exp(fmean(\u001b[38;5;28mmap\u001b[39m(log, data)))\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StatisticsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometric mean requires a non-empty dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    542\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontaining positive numbers\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mStatisticsError\u001b[0m: geometric mean requires a non-empty dataset containing positive numbers"
     ]
    }
   ],
   "source": [
    "ALL_CONFIGS_DIR = \"/home/kant/Documents/experiment_results/2025-11-8_combined_results\"\n",
    "RESULTS = \"mt_kahypar_evo_results\"\n",
    "DIFF = \"evo_diff\"\n",
    "HISTORY = \"evo_history\"\n",
    "DEFAULT_POP_SIZE = 10\n",
    "show_full_history = False\n",
    "\n",
    "\n",
    "# Loop through each folder inside DIR\n",
    "all_geomeans = {}\n",
    "\n",
    "INSTANCES_TO_EXCLUDE = [\"Pd_rhs.mtx.hgr\", \"wb-edu.mtx.hgr\"]\n",
    "\n",
    "for config_dir in glob.glob(ALL_CONFIGS_DIR + \"/*/\"):\n",
    "    config_name = os.path.basename(os.path.normpath(config_dir))\n",
    "    print(f\"Processing configuration: {config_name}\")\n",
    "\n",
    "    config_info = extract_info_from_config(config_name)\n",
    "\n",
    "    k_values = config_info.get('k', None)\n",
    "    kway_value = config_info.get('kway', None)\n",
    "    if kway_value:\n",
    "        kway_value = kway_value[0]\n",
    "    pop_size = config_info.get('pop', None)\n",
    "    \n",
    "\n",
    "    result_dir = os.path.join(config_dir, RESULTS)\n",
    "    diff_dir = os.path.join(config_dir, DIFF)\n",
    "    history_dir = os.path.join(config_dir, HISTORY)\n",
    "    \n",
    "\n",
    "    # Aggregate runs from result files\n",
    "    runs = aggregate_runs(result_dir, instances_to_exclude=INSTANCES_TO_EXCLUDE)\n",
    "    k_runs = split_runs_k_value(runs, *k_values) if k_values else [runs]\n",
    "    k_runs_dict = {}\n",
    "    for i, k in enumerate(k_values):\n",
    "        k_runs_dict[k] = k_runs[i]\n",
    "    \n",
    "    history_runs = aggregate_history_runs(history_dir, full_history=show_full_history, instances_to_exclude=INSTANCES_TO_EXCLUDE)\n",
    "    diff_runs = aggregate_diff_runs(diff_dir, instances_to_exclude=INSTANCES_TO_EXCLUDE)\n",
    "    k_history_runs = split_k_value_history_runs(history_runs, *k_values) if k_values else [history_runs]\n",
    "    k_history_runs_dict = {}\n",
    "    for i, k in enumerate(k_values):\n",
    "        k_history_runs_dict[k] = k_history_runs[i]\n",
    "\n",
    "    # Create Geomeans for each configuration\n",
    "    for k in k_values:\n",
    "        k_run = k_runs_dict[k]\n",
    "        k_history_run = k_history_runs_dict[k]\n",
    "        geomean = create_geomean_over_all_instances(k_history_run)\n",
    "        config = (k, kway_value, pop_size[0] if pop_size else DEFAULT_POP_SIZE)\n",
    "        all_geomeans[config] = geomean\n",
    "\n",
    "# Plot all kway geomans for each k-value in separate plots\n",
    "kway_to_geomeans = {}\n",
    "for (k, kway, pop_size), geomean in all_geomeans.items():\n",
    "    if k not in kway_to_geomeans:\n",
    "        kway_to_geomeans[k] = {}\n",
    "    kway_to_geomeans[k][kway] = geomean\n",
    "    \n",
    "for k, kway_geomeans in kway_to_geomeans.items():\n",
    "    plot_time_series(*kway_geomeans.values(),\n",
    "                     title=f\"Geometric Mean KM1 over Time for k={k}\",\n",
    "                     labels=[f'kway={kway}' for kway in kway_geomeans.keys()]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
