/*******************************************************************************
 * MIT License
 *
 * This file is part of Mt-KaHyPar.
 *
 * Copyright (C) 2020 Tobias Heuer <tobias.heuer@kit.edu>
 * Copyright (C) 2021 Nikolai Maas <nikolai.maas@student.kit.edu>
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 ******************************************************************************/

#include "mt-kahypar/datastructures/dynamic_adjacency_array.h"

#include "mt-kahypar/parallel/atomic_wrapper.h"
#include "mt-kahypar/parallel/parallel_prefix_sum.h"

namespace mt_kahypar {
namespace ds {

IncidentEdgeIterator::IncidentEdgeIterator(
    const HypernodeID u, const DynamicAdjacencyArray *dynamic_adjacency_array,
    const size_t pos, const bool end) :
    _u(u),
    _current_u(u), _current_size(dynamic_adjacency_array->header(u).size()),
    _current_pos(pos), _dynamic_adjacency_array(dynamic_adjacency_array), _end(end)
{
  if(end)
  {
    _current_pos = _current_size;
  }

  ASSERT(pos <= dynamic_adjacency_array->nodeDegree(u));
  traverse_headers();
}

HyperedgeID IncidentEdgeIterator::operator*() const
{
  return _dynamic_adjacency_array->firstActiveEdge(_current_u) + _current_pos;
}

IncidentEdgeIterator &IncidentEdgeIterator::operator++()
{
  ASSERT(!_end);
  ++_current_pos;
  traverse_headers();
  return *this;
}

bool IncidentEdgeIterator::operator!=(const IncidentEdgeIterator &rhs)
{
  return !(*this == rhs);
}

bool IncidentEdgeIterator::operator==(const IncidentEdgeIterator &rhs)
{
  return _u == rhs._u && _end == rhs._end;
}

void IncidentEdgeIterator::traverse_headers()
{
  skip_invalid();
  while(_current_pos >= _current_size)
  {
    const HypernodeID last_u = _current_u;
    _current_u = _dynamic_adjacency_array->header(last_u).it_next;
    _current_pos -= _current_size;
    _current_size = _dynamic_adjacency_array->header(_current_u).size();
    // It can happen that due to a contraction the current vertex
    // we iterate over becomes empty or the head of the current vertex
    // changes. Therefore, we set the end flag if we reach the current
    // head of the list or it_next is equal with the current vertex (means
    // that list becomes empty due to a contraction)
    if(_dynamic_adjacency_array->header(_current_u).is_head || last_u == _current_u)
    {
      _end = true;
      break;
    }
    skip_invalid();
  }
}

void IncidentEdgeIterator::skip_invalid()
{
  while(_current_pos < _current_size && !_dynamic_adjacency_array->edge(**this).isValid())
  {
    ++_current_pos;
  }
}

EdgeIterator::EdgeIterator(const HypernodeID u,
                           const DynamicAdjacencyArray *dynamic_adjacency_array) :
    _current_u(u),
    _current_id(dynamic_adjacency_array->firstActiveEdge(u)),
    _current_last_id(dynamic_adjacency_array->firstInactiveEdge(u)),
    _dynamic_adjacency_array(dynamic_adjacency_array)
{
  traverse_headers();
}

HyperedgeID EdgeIterator::operator*() const { return _current_id; }

EdgeIterator &EdgeIterator::operator++()
{
  ++_current_id;
  traverse_headers();
  return *this;
}

bool EdgeIterator::operator!=(const EdgeIterator &rhs) { return !(*this == rhs); }

bool EdgeIterator::operator==(const EdgeIterator &rhs)
{
  return _current_id == rhs._current_id;
}

void EdgeIterator::traverse_headers()
{
  skip_invalid();
  while(_current_id == _current_last_id &&
        _current_u < _dynamic_adjacency_array->_num_nodes)
  {
    ++_current_u;
    _current_id = _dynamic_adjacency_array->firstActiveEdge(_current_u);
    _current_last_id = _dynamic_adjacency_array->firstInactiveEdge(_current_u);
    skip_invalid();
  }
}

void EdgeIterator::skip_invalid()
{
  while(_current_id < _current_last_id &&
        !_dynamic_adjacency_array->edge(**this).isValid())
  {
    ++_current_id;
  }
}

void DynamicAdjacencyArray::construct(const EdgeVector &edge_vector,
                                      const HyperedgeWeight *edge_weight)
{
  // Accumulate degree of each vertex thread local
  const HyperedgeID num_edges = edge_vector.size();
  ThreadLocalCounter local_incident_nets_per_vertex(_num_nodes + 1, 0);
  Array<HyperedgeID> node_degrees;
  AtomicCounter current_incident_net_pos;
  tbb::parallel_invoke(
      [&] {
        tbb::parallel_for(ID(0), num_edges, [&](const size_t pos) {
          parallel::scalable_vector<size_t> &num_incident_nets_per_vertex =
              local_incident_nets_per_vertex.local();
          ++num_incident_nets_per_vertex[edge_vector[pos].first];
          ++num_incident_nets_per_vertex[edge_vector[pos].second];
        });
      },
      [&] { _header_array.resize(_num_nodes + 1); },
      [&] { _edges.resize(2 * num_edges); },
      [&] { _removable_edges.setSize(2 * num_edges); },
      [&] { _edge_mapping.resize(2 * num_edges); },
      [&] { node_degrees.resize(_num_nodes); },
      [&] {
        current_incident_net_pos.assign(_num_nodes,
                                        parallel::IntegralAtomicWrapper<size_t>(0));
      });

  // We sum up the number of incident nets per vertex only thread local.
  // To obtain the global number of incident nets per vertex, we iterate
  // over each thread local counter and sum it up.
  for(const parallel::scalable_vector<size_t> &c : local_incident_nets_per_vertex)
  {
    tbb::parallel_for(ID(0), _num_nodes,
                      [&](const size_t pos) { node_degrees[pos] += c[pos]; });
  }

  // Compute start positon of the incident nets of each vertex via a parallel prefix sum
  parallel::TBBPrefixSum<HyperedgeID, Array> incident_net_prefix_sum(node_degrees);
  tbb::parallel_scan(tbb::blocked_range<size_t>(ID(0), ID(_num_nodes)),
                     incident_net_prefix_sum);

  // Setup Header of each vertex
  tbb::parallel_for(ID(0), _num_nodes + 1, [&](const HypernodeID u) {
    Header &head = header(u);
    head.prev = u;
    head.next = u;
    head.it_prev = u;
    head.it_next = u;
    head.degree = (u == _num_nodes) ?
                      0 :
                      incident_net_prefix_sum[u + 1] - incident_net_prefix_sum[u];
    head.first = incident_net_prefix_sum[u];
    head.first_active = head.first;
    head.first_inactive = head.first + head.degree;
    head.is_head = true;
  });

  // Insert incident nets into incidence array
  tbb::parallel_for(ID(0), num_edges, [&](const HyperedgeID he) {
    HypernodeID source = edge_vector[he].first;
    HypernodeID target = edge_vector[he].second;
    const HyperedgeWeight weight = edge_weight == nullptr ? 1 : edge_weight[he];
    HyperedgeID id1 = firstEdge(source) + current_incident_net_pos[source].fetch_add(1);
    HyperedgeID id2 = firstEdge(target) + current_incident_net_pos[target].fetch_add(1);
    Edge &e1 = edge(id1);
    e1.source = source;
    e1.target = target;
    e1.weight = weight;
    e1.back_edge = id2;
    Edge &e2 = edge(id2);
    e2.source = target;
    e2.target = source;
    e2.weight = weight;
    e2.back_edge = id1;
  });
}

void DynamicAdjacencyArray::contract(const HypernodeID u, const HypernodeID v,
                                     const AcquireLockFunc &acquire_lock,
                                     const ReleaseLockFunc &release_lock)
{
  // iterate over edges of v and update them
  Header &head_v = header(v);
  for(const HypernodeID &current_v : headers(v))
  {
    const HyperedgeID last = firstInactiveEdge(current_v);
    for(HyperedgeID curr_edge = firstActiveEdge(current_v); curr_edge < last; ++curr_edge)
    {
      Edge &e = edge(curr_edge);
      if(e.isValid() && e.isSinglePin())
      {
        ASSERT(e.source == v);
        e.disable();
        --head_v.degree;
      }
      else if(e.isValid())
      {
        ASSERT(e.source == v && edge(e.back_edge).target == v);
        e.source = u;
        edge(e.back_edge).target = u;
      }
    }
  }

  acquire_lock(u);
  // Concatenate double-linked list of u and v
  append(u, v);
  header(u).degree += head_v.degree;
  ASSERT(verifyIteratorPointers(u),
         "Iterator pointers of vertex" << u << "are corrupted");
  release_lock(u);
}

void DynamicAdjacencyArray::uncontract(const HypernodeID u, const HypernodeID v,
                                       const AcquireLockFunc &acquire_lock,
                                       const ReleaseLockFunc &release_lock)
{
  uncontract(
      u, v, [](HyperedgeID) { return false; }, [](HyperedgeID) {}, [](HyperedgeID) {},
      acquire_lock, release_lock);
}

void DynamicAdjacencyArray::uncontract(const HypernodeID u, const HypernodeID v,
                                       const MarkEdgeFunc &mark_edge,
                                       const CaseOneFunc &case_one_func,
                                       const CaseTwoFunc &case_two_func,
                                       const AcquireLockFunc &acquire_lock,
                                       const ReleaseLockFunc &release_lock)
{
  ASSERT(header(v).prev != v);
  Header &head_u = header(u);
  Header &head_v = header(v);
  acquire_lock(u);
  // Restores the incident list of v to the time before it was appended
  // to the double-linked list of u.
  splice(u, v);
  ASSERT(verifyIteratorPointers(u),
         "Iterator pointers of vertex" << u << "are corrupted");
  ASSERT(head_u.degree >= head_v.degree, V(head_u.degree) << V(head_v.degree));
  head_u.degree -= head_v.degree;
  release_lock(u);

  // iterate over edges of v, update backwards edges and restore removed edges
  HypernodeID last_non_empty_v = v;
  for(const HypernodeID &current_v : headers(v))
  {
    const HyperedgeID first_inactive = firstInactiveEdge(current_v);
    for(HyperedgeID curr_edge = firstActiveEdge(current_v); curr_edge < first_inactive;
        ++curr_edge)
    {
      Edge &e = edge(curr_edge);
      ASSERT(e.source == u || !e.isValid());
      if(e.source == u)
      {
        bool singlePin = false;
        if(e.target == u)
        {
          // If we use a gain cache, it is necessary to correctly attribute
          // which uncontraction changes an edge from single pin to two pins.
          // To achieve this, we introduce a synchronization point with mark_edge.
          singlePin = !mark_edge(curr_edge);
        }
        e.source = v;
        edge(e.back_edge).target = v;
        if(singlePin)
        {
          case_one_func(curr_edge);
        }
        else
        {
          case_two_func(curr_edge);
        }
      }
      else if(e.source == v)
      {
        e.enable();
        ++head_v.degree;
      }
    }

    if(header(current_v).size() > 0)
    {
      restoreItLink(v, last_non_empty_v, current_v);
      last_non_empty_v = current_v;
    }
  }
  ASSERT(verifyIteratorPointers(v),
         "Iterator pointers of vertex" << v << "are corrupted");
}

parallel::scalable_vector<DynamicAdjacencyArray::RemovedEdge>
DynamicAdjacencyArray::removeSinglePinAndParallelEdges()
{
  // TODO(maas): special case for high degree nodes?
  StreamingVector<RemovedEdge> tmp_removed_edges;
  _removable_edges.reset();
  initializeEdgeMapping(_edge_mapping);

  // Step one: We mark each edge that should be removed and
  // update the weight of the representative edges.
  tbb::parallel_for(ID(0), _num_nodes, [&](const HypernodeID u) {
    if(header(u).is_head)
    {
      vec<ParallelEdgeInformation> &local_vec = _thread_local_vec.local();
      local_vec.clear();

      // mark single pin/invalid edges and sort all other incident edges
      for(const HypernodeID &current_u : headers(u))
      {
        const HyperedgeID first_inactive = firstInactiveEdge(current_u);
        for(HyperedgeID id = firstActiveEdge(current_u); id < first_inactive; ++id)
        {
          const Edge &e = edge(id);
          if(e.isValid() && !e.isSinglePin())
          {
            local_vec.emplace_back(e.target, id, uniqueEdgeID(id));
          }
          else
          {
            _removable_edges.set(id, true);
            if(e.isValid())
            {
              --header(u).degree;
            }
          }
        }
      }
      std::sort(local_vec.begin(), local_vec.end(), [](const auto &e1, const auto &e2) {
        // we need a symmetric order on edges and backedges to ensure that the
        // kept forward and backward edge are actually the same edge
        return e1.target < e2.target ||
               (e1.target == e2.target && e1.unique_id < e2.unique_id);
      });

      // mark all duplicate edges and update weight
      if(!local_vec.empty())
      {
        HyperedgeID current_representative = local_vec[0].edge_id;
        for(size_t i = 0; i + 1 < local_vec.size(); ++i)
        {
          const ParallelEdgeInformation &e1 = local_vec[i];
          const ParallelEdgeInformation &e2 = local_vec[i + 1];
          ASSERT(e2.target != kInvalidHypernode && e2.target != u);
          if(e1.target == e2.target)
          {
            // we abuse the source to save the representative edge
            edge(e2.edge_id).source = current_representative;
            edge(current_representative).weight += edge(e2.edge_id).weight;
            _removable_edges.set(e2.edge_id, true);
            --header(u).degree;
          }
          else
          {
            current_representative = e2.edge_id;
          }
        }
      }
    }
  });

  // Step two: Swap each marked edge and update the edge mapping accordingly.
  tbb::parallel_for(ID(0), _num_nodes, [&](const HypernodeID u) {
    Header &head = header(u);
    const HyperedgeID first_inactive = firstInactiveEdge(u);
    for(HyperedgeID e = firstActiveEdge(u); e < first_inactive; ++e)
    {
      if(_removable_edges[e])
      {
        const HyperedgeID new_id = firstActiveEdge(u);
        swapAndUpdateMapping(e, new_id);
        ++head.first_active;
        tmp_removed_edges.stream(RemovedEdge{ new_id, e });
      }
    }

    if(head.size() == 0 && !head.is_head)
    {
      head.it_next = u;
      head.it_prev = u;
    }
  });

  // Step three: Update iterator pointers and back edges, collect removed edges.
  vec<RemovedEdge> removed_edges;
  tbb::parallel_invoke(
      [&]() {
        tbb::parallel_for(ID(0), _num_nodes, [&](const HypernodeID u) {
          if(header(u).is_head)
          {
            restoreIteratorPointers(u);
          }
        });
      },
      [&]() { applyEdgeMapping(_edge_mapping); },
      [&]() {
        removed_edges = tmp_removed_edges.copy_parallel();
        tmp_removed_edges.clear_parallel();
      });

  HEAVY_COARSENING_ASSERT(verifyBackEdges());
  return removed_edges;
}

void DynamicAdjacencyArray::restoreSinglePinAndParallelEdges(
    const parallel::scalable_vector<DynamicAdjacencyArray::RemovedEdge> &edges_to_restore)
{
  _removable_edges.reset();
  initializeEdgeMapping(_edge_mapping);

  // Step one: We mark all edges that need to be restored and save their swap target.
  tbb::parallel_for(UL(0), edges_to_restore.size(), [&](const size_t i) {
    const RemovedEdge &re = edges_to_restore[i];
    _removable_edges.set(re.edge_id, true);
    // we abuse the edge mapping to save the swap target
    _edge_mapping[re.edge_id] = re.old_id;
  });

  // Step two: We swap each marked edge (in reverse order to
  // removeSinglePinAndParallelEdges), update the edge mapping accordingly and mark the
  // edge again.
  tbb::parallel_for(ID(0), _num_nodes, [&](const HypernodeID u) {
    Header &head = header(u);
    const HyperedgeID first = firstEdge(u);
    for(HyperedgeID curr = firstActiveEdge(u); curr > first && _removable_edges[curr - 1];
        --curr)
    {
      const HyperedgeID e = curr - 1;
      _removable_edges.set(e, false);
      _removable_edges.set(_edge_mapping[e], true);
      swapAndUpdateMapping(e, _edge_mapping[e]);
      --head.first_active;
    }
  });

  // Step three: We update the node degrees, restore iterator pointers and the weights
  // of the representatives and update the back edges.
  tbb::parallel_invoke(
      [&]() {
        tbb::parallel_for(ID(0), _num_nodes, [&](const HypernodeID u) {
          if(header(u).is_head)
          {
            bool restore_it = false;
            for(const HypernodeID &current_u : headers(u))
            {
              HyperedgeID num_restored = 0;
              const HyperedgeID first_inactive = firstInactiveEdge(current_u);
              for(HyperedgeID id = firstActiveEdge(current_u); id < first_inactive; ++id)
              {
                Edge &e = edge(id);
                // Note: We use e.target to check whether it is a single pin edge.
                // Comparing e.source and e.target does not work, because e.source
                // currently holds the representative edge and the id of the
                // representative could accidentially be equal to e.target.
                if(_removable_edges[id] && e.isValid() && e.target != u)
                {
                  Edge &representative = edge(e.source);
                  representative.weight -= e.weight;
                  e.source = u;
                }
                else if(e.isValid())
                {
                  ASSERT(e.source == u);
                }
                if(_removable_edges[id] && e.isValid())
                {
                  ++num_restored;
                }
              }
              header(u).degree += num_restored;
              restore_it |= (num_restored > 0);
            }

            if(restore_it)
            {
              restoreIteratorPointers(u);
            }
          }
        });
      },
      [&]() { applyEdgeMapping(_edge_mapping); });

  HEAVY_REFINEMENT_ASSERT(verifyBackEdges());
}

void DynamicAdjacencyArray::reset()
{
  // Nothing to do here
}

void DynamicAdjacencyArray::sortIncidentEdges()
{
  // this is a bit complicated because we need to update the back edges
  Array<HyperedgeID> edge_permutation;
  edge_permutation.resize(_edges.size());
  initializeEdgeMapping(edge_permutation);

  tbb::parallel_for(ID(0), ID(_header_array.size()), [&](HypernodeID u) {
    // sort mapped indizes
    const HyperedgeID start = firstActiveEdge(u);
    const HyperedgeID end = firstInactiveEdge(u);
    std::sort(edge_permutation.data() + start, edge_permutation.data() + end,
              [&](const auto &e1, const auto &e2) {
                return edge(e1).target < edge(e2).target;
              });

    // apply permutation
    for(size_t i = start; i < end; ++i)
    {
      HyperedgeID target = edge_permutation[i];
      while(target < i)
      {
        target = edge_permutation[target];
      }
      std::swap(_edges[i], _edges[target]);
    }
  });

  // we need the reversed permutation for the back edges
  tbb::parallel_for(ID(0), ID(edge_permutation.size()),
                    [&](const HyperedgeID e) { _edge_mapping[edge_permutation[e]] = e; });
  applyEdgeMapping(_edge_mapping);

  HEAVY_PREPROCESSING_ASSERT(verifyBackEdges());
}

DynamicAdjacencyArray DynamicAdjacencyArray::copy(parallel_tag_t) const
{
  DynamicAdjacencyArray adjacency_array;
  adjacency_array._num_nodes = _num_nodes;

  tbb::parallel_invoke(
      [&] {
        adjacency_array._header_array.resize(_header_array.size());
        memcpy(adjacency_array._header_array.data(), _header_array.data(),
               sizeof(Header) * _header_array.size());
      },
      [&] {
        adjacency_array._edges.resize(_edges.size());
        memcpy(adjacency_array._edges.data(), _edges.data(),
               sizeof(Edge) * _edges.size());
      },
      [&] { adjacency_array._removable_edges.setSize(_edges.size()); },
      [&] { adjacency_array._edge_mapping.resize(_edge_mapping.size()); });

  return adjacency_array;
}

DynamicAdjacencyArray DynamicAdjacencyArray::copy() const
{
  DynamicAdjacencyArray adjacency_array;
  adjacency_array._num_nodes = _num_nodes;

  adjacency_array._header_array.resize(_header_array.size());
  memcpy(adjacency_array._header_array.data(), _header_array.data(),
         sizeof(Header) * _header_array.size());
  adjacency_array._edges.resize(_edges.size());
  memcpy(adjacency_array._edges.data(), _edges.data(), sizeof(Edge) * _edges.size());
  adjacency_array._removable_edges.setSize(_edges.size());
  adjacency_array._edge_mapping.resize(_edge_mapping.size());
  return adjacency_array;
}

void DynamicAdjacencyArray::swapAndUpdateMapping(const HyperedgeID e,
                                                 const HyperedgeID new_id)
{
  HyperedgeID permutation_source = new_id;
  while(_edge_mapping[permutation_source] != new_id)
  {
    permutation_source = _edge_mapping[permutation_source];
  }
  ASSERT(_edge_mapping[permutation_source] == new_id);
  std::swap(edge(e), edge(new_id));
  _edge_mapping[e] = new_id;
  _edge_mapping[permutation_source] = e;
}

void DynamicAdjacencyArray::append(const HypernodeID u, const HypernodeID v)
{
  const HypernodeID tail_u = header(u).prev;
  const HypernodeID tail_v = header(v).prev;
  header(tail_u).next = v;
  header(v).prev = tail_u;
  header(tail_v).next = u;
  header(u).prev = tail_v;

  const HypernodeID it_tail_u = header(u).it_prev;
  const HypernodeID it_tail_v = header(v).it_prev;
  header(it_tail_u).it_next = v;
  header(v).it_prev = it_tail_u;
  header(it_tail_v).it_next = u;
  header(u).it_prev = it_tail_v;

  header(v).tail = tail_v;
  header(v).is_head = false;

  if(header(v).size() == 0)
  {
    removeEmptyIncidentEdgeList(v);
  }
}

void DynamicAdjacencyArray::splice(const HypernodeID u, const HypernodeID v)
{
  // Restore the iterator double-linked list of u such that it does not contain
  // any incident net list of v
  const HypernodeID tail = header(v).tail;
  HypernodeID non_empty_entry_prev_v = v;
  HypernodeID non_empty_entry_next_tail = tail;
  while((non_empty_entry_prev_v == v || header(non_empty_entry_prev_v).size() == 0) &&
        non_empty_entry_prev_v != u)
  {
    non_empty_entry_prev_v = header(non_empty_entry_prev_v).prev;
  }
  while((non_empty_entry_next_tail == tail ||
         header(non_empty_entry_next_tail).size() == 0) &&
        non_empty_entry_next_tail != u)
  {
    non_empty_entry_next_tail = header(non_empty_entry_next_tail).next;
  }
  header(non_empty_entry_prev_v).it_next = non_empty_entry_next_tail;
  header(non_empty_entry_next_tail).it_prev = non_empty_entry_prev_v;

  // Cut out incident list of v
  const HypernodeID prev_v = header(v).prev;
  const HypernodeID next_tail = header(tail).next;
  header(v).prev = tail;
  header(tail).next = v;
  header(next_tail).prev = prev_v;
  header(prev_v).next = next_tail;
  header(v).is_head = true;
}

void DynamicAdjacencyArray::removeEmptyIncidentEdgeList(const HypernodeID u)
{
  ASSERT(!header(u).is_head);
  ASSERT(header(u).size() == 0, V(u) << V(header(u).size()));
  Header &head = header(u);
  header(head.it_prev).it_next = head.it_next;
  header(head.it_next).it_prev = head.it_prev;
  head.it_next = u;
  head.it_prev = u;
}

void DynamicAdjacencyArray::restoreIteratorPointers(const HypernodeID u)
{
  ASSERT(header(u).is_head);
  HypernodeID last_non_empty_u = u;
  for(const HypernodeID &current_u : headers(u))
  {
    if(header(current_u).size() > 0 || current_u == u)
    {
      restoreItLink(u, last_non_empty_u, current_u);
      last_non_empty_u = current_u;
    }
  }
  ASSERT(verifyIteratorPointers(u));
}

void DynamicAdjacencyArray::restoreItLink(const HypernodeID u, const HypernodeID prev,
                                          const HypernodeID current)
{
  header(prev).it_next = current;
  header(current).it_prev = prev;
  header(current).it_next = u;
  header(u).it_prev = current;
}

bool DynamicAdjacencyArray::verifyIteratorPointers(const HypernodeID u) const
{
  HypernodeID current_u = u;
  HypernodeID last_non_empty_entry = kInvalidHypernode;
  do
  {
    if(header(current_u).size() > 0 || current_u == u)
    {
      if(last_non_empty_entry != kInvalidHypernode)
      {
        if(header(current_u).it_prev != last_non_empty_entry)
        {
          return false;
        }
        else if(header(last_non_empty_entry).it_next != current_u)
        {
          return false;
        }
      }
      last_non_empty_entry = current_u;
    }
    else
    {
      if(header(current_u).it_next != current_u)
      {
        return false;
      }
      else if(header(current_u).it_prev != current_u)
      {
        return false;
      }
    }

    current_u = header(current_u).next;
  } while(current_u != u);

  if(header(u).it_prev != last_non_empty_entry)
  {
    return false;
  }
  else if(header(last_non_empty_entry).it_next != u)
  {
    return false;
  }

  return true;
}

bool DynamicAdjacencyArray::verifyBackEdges() const
{
  for(HyperedgeID e = 0; e < _edges.size(); ++e)
  {
    if(edge(edge(e).back_edge).back_edge != e)
    {
      return false;
    }
  }
  return true;
}

} // namespace ds
} // namespace mt_kahypar
