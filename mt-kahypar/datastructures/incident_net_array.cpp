/*******************************************************************************
 * MIT License
 *
 * This file is part of Mt-KaHyPar.
 *
 * Copyright (C) 2020 Lars Gottesb√ºren <lars.gottesbueren@kit.edu>
 * Copyright (C) 2020 Tobias Heuer <tobias.heuer@kit.edu>
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 ******************************************************************************/

#include "mt-kahypar/datastructures/incident_net_array.h"

#include "mt-kahypar/parallel/parallel_prefix_sum.h"

namespace mt_kahypar {
namespace ds {

IncidentNetIterator::IncidentNetIterator(const HypernodeID u,
                                         const IncidentNetArray *incident_net_array,
                                         const size_t pos, const bool end) :
    _u(u),
    _current_u(u), _current_size(incident_net_array->header(u)->size), _current_pos(0),
    _incident_net_array(incident_net_array), _end(end)
{
  if(end)
  {
    _current_pos = _current_size;
  }

  if(!end && _current_pos == _current_size)
  {
    next_iterator();
  }

  if(pos > 0)
  {
    ASSERT(pos <= incident_net_array->nodeDegree(u));
    size_t c_pos = pos;
    while(c_pos != 0)
    {
      const size_t current_size = _current_size;
      if(c_pos >= current_size)
      {
        c_pos -= current_size;
        _current_pos = current_size;
        next_iterator();
      }
      else
      {
        _current_pos = c_pos;
        c_pos = 0;
      }
    }
  }
}

HyperedgeID IncidentNetIterator::operator*() const
{
  ASSERT(!_end);
  return _incident_net_array->firstEntry(_current_u)[_current_pos].e;
}

IncidentNetIterator &IncidentNetIterator::operator++()
{
  ASSERT(!_end);
  ++_current_pos;
  if(_current_pos == _current_size)
  {
    next_iterator();
  }
  return *this;
}

bool IncidentNetIterator::operator!=(const IncidentNetIterator &rhs)
{
  return _u != rhs._u || _end != rhs._end;
}

bool IncidentNetIterator::operator==(const IncidentNetIterator &rhs)
{
  return _u == rhs._u && _end == rhs._end;
}

void IncidentNetIterator::next_iterator()
{
  while(_current_pos == _current_size)
  {
    const HypernodeID last_u = _current_u;
    _current_u = _incident_net_array->header(_current_u)->it_next;
    _current_pos = 0;
    _current_size = _incident_net_array->header(_current_u)->size;
    // It can happen that due to a contraction the current vertex
    // we iterate over becomes empty or the head of the current vertex
    // changes. Therefore, we set the end flag if we reach the current
    // head of the list or it_next is equal with the current vertex (means
    // that list becomes empty due to a contraction)
    if(_incident_net_array->header(_current_u)->is_head || last_u == _current_u)
    {
      _end = true;
      break;
    }
  }
}

// ! Contracts two incident list of u and v, whereby u is the representative and
// ! v the contraction partner of the contraction. The contraction involves to remove
// ! all incident nets shared between u and v from the incident net list of v and append
// ! the list of v to u.
void IncidentNetArray::contract(
    const HypernodeID u, const HypernodeID v,
    const kahypar::ds::FastResetFlagArray<> &shared_hes_of_u_and_v,
    const AcquireLockFunc &acquire_lock, const ReleaseLockFunc &release_lock)
{
  // Remove all HEs flagged in shared_hes_of_u_and_v from v
  removeIncidentNets(v, shared_hes_of_u_and_v);

  acquire_lock(u);
  // Concatenate double-linked list of u and v
  append(u, v);
  header(u)->degree += header(v)->degree;
  ASSERT(verifyIteratorPointers(u),
         "Iterator pointers of vertex" << u << "are corrupted");
  release_lock(u);
}

// ! Uncontract two previously contracted vertices u and v.
// ! Uncontraction involves to decrement the version number of all incident lists
// contained ! in v and restore all incident nets with a version number equal to the new
// version. ! Note, uncontraction must be done in relative contraction order
void IncidentNetArray::uncontract(const HypernodeID u, const HypernodeID v,
                                  const AcquireLockFunc &acquire_lock,
                                  const ReleaseLockFunc &release_lock)
{
  uncontract(
      u, v, [](HyperedgeID) {}, [](HyperedgeID) {}, acquire_lock, release_lock);
}

// ! Uncontract two previously contracted vertices u and v.
// ! Uncontraction involves to decrement the version number of all incident lists
// contained ! in v and restore all incident nets with a version number equal to the new
// version. ! Additionally it calls case_one_func for a hyperedge he, if u and v were
// previously both ! adjacent to he and case_two_func if only v was previously adjacent to
// he. ! Note, uncontraction must be done in relative contraction order
void IncidentNetArray::uncontract(const HypernodeID u, const HypernodeID v,
                                  const CaseOneFunc &case_one_func,
                                  const CaseTwoFunc &case_two_func,
                                  const AcquireLockFunc &acquire_lock,
                                  const ReleaseLockFunc &release_lock)
{
  ASSERT(header(v)->prev != v);
  Header *head_v = header(v);
  acquire_lock(u);
  // Restores the incident list of v to the time before it was appended
  // to the double-linked list of u.
  splice(u, v);
  header(u)->degree -= head_v->degree;
  ASSERT(verifyIteratorPointers(u),
         "Iterator pointers of vertex" << u << "are corrupted");
  release_lock(u);

  // Restore all incident nets of v removed by the contraction of u and v
  restoreIncidentNets(v, case_one_func, case_two_func);
}

// ! Removes all incidents nets of u flagged in hes_to_remove.
void IncidentNetArray::removeIncidentNets(
    const HypernodeID u, const kahypar::ds::FastResetFlagArray<> &hes_to_remove)
{
  HypernodeID current_u = u;
  Header *head_u = header(u);
  do
  {
    Header *head = header(current_u);
    const HypernodeID new_version = ++head->current_version;
    Entry *last_entry = lastEntry(current_u);
    for(Entry *current_entry = firstEntry(current_u); current_entry != last_entry;
        ++current_entry)
    {
      if(hes_to_remove[current_entry->e])
      {
        // Hyperedge should be removed => decrement size of incident net list
        swap(current_entry--, --last_entry);
        ASSERT(head->size > 0);
        --head->size;
        --head_u->degree;
      }
      else
      {
        // Vertex is non-shared between u and v => adapt version number of current
        // incident net
        current_entry->version = new_version;
      }
    }

    if(head->size == 0 && current_u != u)
    {
      // Current list becomes empty => remove it from the iterator double linked list
      // such that iteration over the incident nets is more efficient
      removeEmptyIncidentNetList(current_u);
    }
    current_u = head->next;
  } while(current_u != u);
  ASSERT(verifyIteratorPointers(u),
         "Iterator pointers of vertex" << u << "are corrupted");
}

// ! Restores all previously removed incident nets
// ! Note, function must be called in reverse order of calls to
// ! removeIncidentNets(...) and all uncontraction that happens
// ! between two consecutive calls to removeIncidentNets(...) must
// ! be processed.
void IncidentNetArray::restoreIncidentNets(const HypernodeID u)
{
  restoreIncidentNets(
      u, [](HyperedgeID) {}, [](HyperedgeID) {});
}

// ! Restores all previously removed incident nets
// ! Note, function must be called in reverse order of calls to
// ! removeIncidentNets(...) and all uncontraction that happens
// ! between two consecutive calls to removeIncidentNets(...) must
// ! be processed.
void IncidentNetArray::restoreIncidentNets(const HypernodeID u,
                                           const CaseOneFunc &case_one_func,
                                           const CaseTwoFunc &case_two_func)
{
  Header *head_u = header(u);
  HypernodeID current_u = u;
  HypernodeID last_non_empty_entry = kInvalidHypernode;
  do
  {
    Header *head = header(current_u);
    ASSERT(head->current_version > 0);
    const HypernodeID new_version = --head->current_version;

    // Iterate over all active entries and call case_two_func
    // => After an uncontraction only u was part of them not its representative
    for(Entry *current_entry = firstEntry(current_u);
        current_entry != lastEntry(current_u); ++current_entry)
    {
      case_two_func(current_entry->e);
    }

    // Iterate over non-active entries (and activate them) until the version number
    // is not equal to the new version of the list
    const Entry *last_entry = reinterpret_cast<const Entry *>(header(current_u + 1));
    for(Entry *current_entry = lastEntry(current_u); current_entry != last_entry;
        ++current_entry)
    {
      if(current_entry->version == new_version)
      {
        ++head->size;
        ++head_u->degree;
        case_one_func(current_entry->e);
      }
      else
      {
        break;
      }
    }

    // Restore iterator double-linked list which only contains
    // non-empty incident net lists
    if(head->size > 0 || current_u == u)
    {
      if(last_non_empty_entry != kInvalidHypernode &&
         head->it_prev != last_non_empty_entry)
      {
        header(last_non_empty_entry)->it_next = current_u;
        head->it_prev = last_non_empty_entry;
      }
      last_non_empty_entry = current_u;
    }
    current_u = head->next;
  } while(current_u != u);

  ASSERT(last_non_empty_entry != kInvalidHypernode);
  head_u->it_prev = last_non_empty_entry;
  header(last_non_empty_entry)->it_next = u;
  ASSERT(verifyIteratorPointers(u),
         "Iterator pointers of vertex" << u << "are corrupted");
}

IncidentNetArray IncidentNetArray::copy(parallel_tag_t) const
{
  IncidentNetArray incident_nets;
  incident_nets._num_hypernodes = _num_hypernodes;
  incident_nets._size_in_bytes = _size_in_bytes;

  tbb::parallel_invoke(
      [&] {
        incident_nets._index_array.resize(_index_array.size());
        memcpy(incident_nets._index_array.data(), _index_array.data(),
               sizeof(size_t) * _index_array.size());
      },
      [&] {
        incident_nets._incident_net_array = parallel::make_unique<char>(_size_in_bytes);
        memcpy(incident_nets._incident_net_array.get(), _incident_net_array.get(),
               _size_in_bytes);
      });

  return incident_nets;
}

IncidentNetArray IncidentNetArray::copy() const
{
  IncidentNetArray incident_nets;
  incident_nets._num_hypernodes = _num_hypernodes;
  incident_nets._size_in_bytes = _size_in_bytes;
  incident_nets._index_array.resize(_index_array.size());
  memcpy(incident_nets._index_array.data(), _index_array.data(),
         sizeof(size_t) * _index_array.size());
  incident_nets._incident_net_array = parallel::make_unique<char>(_size_in_bytes);
  memcpy(incident_nets._incident_net_array.get(), _incident_net_array.get(),
         _size_in_bytes);
  return incident_nets;
}

void IncidentNetArray::reset()
{
  tbb::parallel_for(ID(0), _num_hypernodes, [&](const HypernodeID u) {
    header(u)->current_version = 0;
    for(Entry *entry = firstEntry(u); entry != lastEntry(u); ++entry)
    {
      entry->version = 0;
    }
  });
}

void IncidentNetArray::append(const HypernodeID u, const HypernodeID v)
{
  const HypernodeID tail_u = header(u)->prev;
  const HypernodeID tail_v = header(v)->prev;
  header(tail_u)->next = v;
  header(u)->prev = tail_v;
  header(v)->tail = tail_v;
  header(v)->prev = tail_u;
  header(tail_v)->next = u;

  const HypernodeID it_tail_u = header(u)->it_prev;
  const HypernodeID it_tail_v = header(v)->it_prev;
  header(it_tail_u)->it_next = v;
  header(u)->it_prev = it_tail_v;
  header(v)->it_prev = it_tail_u;
  header(it_tail_v)->it_next = u;
  header(v)->is_head = false;

  if(header(v)->size == 0)
  {
    removeEmptyIncidentNetList(v);
  }
}

void IncidentNetArray::splice(const HypernodeID u, const HypernodeID v)
{
  // Restore the iterator double-linked list of u such that it does not contain
  // any incident net list of v
  const HypernodeID tail = header(v)->tail;
  HypernodeID non_empty_entry_prev_v = v;
  HypernodeID non_empty_entry_next_tail = tail;
  while((non_empty_entry_prev_v == v || header(non_empty_entry_prev_v)->size == 0) &&
        non_empty_entry_prev_v != u)
  {
    non_empty_entry_prev_v = header(non_empty_entry_prev_v)->prev;
  }
  while((non_empty_entry_next_tail == tail ||
         header(non_empty_entry_next_tail)->size == 0) &&
        non_empty_entry_next_tail != u)
  {
    non_empty_entry_next_tail = header(non_empty_entry_next_tail)->next;
  }
  header(non_empty_entry_prev_v)->it_next = non_empty_entry_next_tail;
  header(non_empty_entry_next_tail)->it_prev = non_empty_entry_prev_v;

  // Cut out incident list of v
  const HypernodeID prev_v = header(v)->prev;
  const HypernodeID next_tail = header(tail)->next;
  header(v)->prev = tail;
  header(tail)->next = v;
  header(next_tail)->prev = prev_v;
  header(prev_v)->next = next_tail;
  header(v)->is_head = true;
}

void IncidentNetArray::removeEmptyIncidentNetList(const HypernodeID u)
{
  ASSERT(!header(u)->is_head);
  ASSERT(header(u)->size == 0, V(u) << V(header(u)->size));
  Header *head = header(u);
  header(head->it_prev)->it_next = head->it_next;
  header(head->it_next)->it_prev = head->it_prev;
  head->it_next = u;
  head->it_prev = u;
}

void IncidentNetArray::construct(const HyperedgeVector &edge_vector)
{
  // Accumulate degree of each vertex thread local
  const HyperedgeID num_hyperedges = edge_vector.size();
  ThreadLocalCounter local_incident_nets_per_vertex(_num_hypernodes + 1, 0);
  AtomicCounter current_incident_net_pos;
  tbb::parallel_invoke(
      [&] {
        tbb::parallel_for(ID(0), num_hyperedges, [&](const size_t pos) {
          parallel::scalable_vector<size_t> &num_incident_nets_per_vertex =
              local_incident_nets_per_vertex.local();
          for(const HypernodeID &pin : edge_vector[pos])
          {
            ASSERT(pin < _num_hypernodes, V(pin) << V(_num_hypernodes));
            ++num_incident_nets_per_vertex[pin + 1];
          }
        });
      },
      [&] {
        _index_array.assign(_num_hypernodes + 1, sizeof(Header));
        current_incident_net_pos.assign(_num_hypernodes,
                                        parallel::IntegralAtomicWrapper<size_t>(0));
      });

  // We sum up the number of incident nets per vertex only thread local.
  // To obtain the global number of incident nets per vertex, we iterate
  // over each thread local counter and sum it up.
  for(const parallel::scalable_vector<size_t> &c : local_incident_nets_per_vertex)
  {
    tbb::parallel_for(ID(0), _num_hypernodes + 1, [&](const size_t pos) {
      _index_array[pos] += c[pos] * sizeof(Entry);
    });
  }

  // Compute start positon of the incident nets of each vertex via a parallel prefix sum
  parallel::TBBPrefixSum<size_t, Array> incident_net_prefix_sum(_index_array);
  tbb::parallel_scan(tbb::blocked_range<size_t>(UL(0), UI64(_num_hypernodes + 1)),
                     incident_net_prefix_sum);
  _size_in_bytes = incident_net_prefix_sum.total_sum();
  _incident_net_array = parallel::make_unique<char>(_size_in_bytes);

  // Insert incident nets into incidence array
  tbb::parallel_for(ID(0), num_hyperedges, [&](const HyperedgeID he) {
    for(const HypernodeID &pin : edge_vector[he])
    {
      Entry *entry = firstEntry(pin) + current_incident_net_pos[pin]++;
      entry->e = he;
      entry->version = 0;
    }
  });

  // Setup Header of each vertex
  tbb::parallel_for(ID(0), _num_hypernodes, [&](const HypernodeID u) {
    Header *head = header(u);
    head->prev = u;
    head->next = u;
    head->it_prev = u;
    head->it_next = u;
    head->size = current_incident_net_pos[u].load(std::memory_order_relaxed);
    head->degree = head->size;
    head->current_version = 0;
    head->is_head = true;
  });
}

bool IncidentNetArray::verifyIteratorPointers(const HypernodeID u) const
{
  HypernodeID current_u = u;
  HypernodeID last_non_empty_entry = kInvalidHypernode;
  do
  {
    if(header(current_u)->size > 0 || current_u == u)
    {
      if(last_non_empty_entry != kInvalidHypernode)
      {
        if(header(current_u)->it_prev != last_non_empty_entry)
        {
          return false;
        }
        else if(header(last_non_empty_entry)->it_next != current_u)
        {
          return false;
        }
      }
      last_non_empty_entry = current_u;
    }
    else
    {
      if(header(current_u)->it_next != current_u)
      {
        return false;
      }
      else if(header(current_u)->it_prev != current_u)
      {
        return false;
      }
    }

    current_u = header(current_u)->next;
  } while(current_u != u);

  if(header(u)->it_prev != last_non_empty_entry)
  {
    return false;
  }
  else if(header(last_non_empty_entry)->it_next != u)
  {
    return false;
  }

  return true;
}

} // namespace ds
} // namespace mt_kahypar