/*******************************************************************************
 * MIT License
 *
 * This file is part of Mt-KaHyPar.
 *
 * Copyright (C) 2023 Tobias Heuer <tobias.heuer@kit.edu>
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 ******************************************************************************/

#include "mt-kahypar/partition/refinement/gains/steiner_tree/steiner_tree_gain_cache.h"

#include "tbb/concurrent_vector.h"
#include "tbb/enumerable_thread_specific.h"
#include "tbb/parallel_for.h"

#include "mt-kahypar/definitions.h"

namespace mt_kahypar {

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::initializeGainCache(
    const PartitionedHypergraph &partitioned_hg)
{
  ASSERT(!_is_initialized, "Gain cache is already initialized");
  ASSERT(_k <= 0 || _k >= partitioned_hg.k(),
         "Gain cache was already initialized for a different k" << V(_k)
                                                                << V(partitioned_hg.k()));
  allocateGainTable(partitioned_hg.topLevelNumNodes(), partitioned_hg.topLevelNumEdges(),
                    partitioned_hg.k());
  initializeAdjacentBlocks(partitioned_hg);

  // Compute gain of all nodes
  tbb::parallel_for(
      tbb::blocked_range<HypernodeID>(HypernodeID(0), partitioned_hg.initialNumNodes()),
      [&](tbb::blocked_range<HypernodeID> &r) {
        vec<HyperedgeWeight> &benefit_aggregator = _ets_benefit_aggregator.local();
        for(HypernodeID u = r.begin(); u < r.end(); ++u)
        {
          if(partitioned_hg.nodeIsEnabled(u))
          {
            initializeGainCacheEntryForNode(partitioned_hg, u, benefit_aggregator);
          }
        }
      });

  _is_initialized = true;
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::initializeGainCacheEntryForNode(
    const PartitionedHypergraph &partitioned_hg, const HypernodeID hn)
{
  vec<HyperedgeWeight> &benefit_aggregator = _ets_benefit_aggregator.local();
  initializeAdjacentBlocksOfNode(partitioned_hg, hn);
  initializeGainCacheEntryForNode(partitioned_hg, hn, benefit_aggregator);
}

bool SteinerTreeGainCache::triggersDeltaGainUpdate(
    const SynchronizedEdgeUpdate &sync_update)
{
  return sync_update.pin_count_in_from_part_after == 0 ||
         sync_update.pin_count_in_from_part_after == 1 ||
         sync_update.pin_count_in_to_part_after == 1 ||
         sync_update.pin_count_in_to_part_after == 2;
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::notifyBeforeDeltaGainUpdate(
    const PartitionedHypergraph &, const SynchronizedEdgeUpdate &sync_update)
{
  if(triggersDeltaGainUpdate(sync_update))
  {
    ASSERT(UL(sync_update.he) < _version.size());
    // The move will induce a gain cache update. In this case, we increment the version ID
    // of the hyperedge such that concurrent running initializations of gain entries are
    // notified and rerun the initialization step if this affected the gain computation.
    ++_version[sync_update.he].version;
  }
}

namespace {
MT_KAHYPAR_ATTRIBUTE_ALWAYS_INLINE
HyperedgeWeight gainOfHyperedge(const PartitionID from, const PartitionID to,
                                const HyperedgeWeight edge_weight,
                                const TargetGraph &target_graph,
                                ds::PinCountSnapshot &pin_counts,
                                ds::Bitset &connectivity_set)
{
  const HypernodeID pin_count_in_from_part = pin_counts.pinCountInPart(from);
  const HyperedgeWeight current_distance = target_graph.distance(connectivity_set);
  if(pin_count_in_from_part == 1)
  {
    ASSERT(connectivity_set.isSet(from));
    connectivity_set.unset(from);
  }
  const HyperedgeWeight distance_with_to =
      target_graph.distanceWithBlock(connectivity_set, to);
  if(pin_count_in_from_part == 1)
  {
    connectivity_set.set(from);
  }
  return (current_distance - distance_with_to) * edge_weight;
}

MT_KAHYPAR_ATTRIBUTE_ALWAYS_INLINE
void reconstructConnectivitySetAndPinCountsBeforeMove(
    const SynchronizedEdgeUpdate &sync_update, ds::Bitset &connectivity_set,
    ds::PinCountSnapshot &pin_counts)
{
  if(sync_update.pin_count_in_from_part_after == 0)
  {
    ASSERT(!connectivity_set.isSet(sync_update.from));
    connectivity_set.set(sync_update.from);
  }
  if(sync_update.pin_count_in_to_part_after == 1)
  {
    ASSERT(connectivity_set.isSet(sync_update.to));
    connectivity_set.unset(sync_update.to);
  }
  pin_counts.setPinCountInPart(sync_update.from,
                               sync_update.pin_count_in_from_part_after + 1);
  pin_counts.setPinCountInPart(sync_update.to,
                               sync_update.pin_count_in_to_part_after - 1);
}
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::deltaGainUpdate(const PartitionedHypergraph &partitioned_hg,
                                           const SynchronizedEdgeUpdate &sync_update)
{
  ASSERT(_is_initialized, "Gain cache is not initialized");
  ASSERT(sync_update.connectivity_set_after);
  ASSERT(sync_update.pin_counts_after);
  ASSERT(sync_update.target_graph);

  if(triggersDeltaGainUpdate(sync_update))
  {
    const HyperedgeID he = sync_update.he;
    const PartitionID from = sync_update.from;
    const PartitionID to = sync_update.to;
    const HyperedgeWeight edge_weight = sync_update.edge_weight;
    const HypernodeID pin_count_in_from_part_after =
        sync_update.pin_count_in_from_part_after;
    const HypernodeID pin_count_in_to_part_after = sync_update.pin_count_in_to_part_after;
    const TargetGraph &target_graph = *sync_update.target_graph;
    ds::Bitset &connectivity_set = *sync_update.connectivity_set_after;
    ds::PinCountSnapshot &pin_counts = *sync_update.pin_counts_after;

    if(pin_count_in_from_part_after == 0 || pin_count_in_to_part_after == 1)
    {
      // Connectivity set has changed
      // => Recompute gain of hyperedge for all pins and their adjacent blocks

      // Compute new gain of hyperedge for all pins and their adjacent blocks and
      // add it to the gain cache entries
      for(const HypernodeID &pin : partitioned_hg.pins(he))
      {
        const PartitionID source = partitioned_hg.partID(pin);
        for(const PartitionID &target : _adjacent_blocks.connectivitySet(pin))
        {
          if(source != target)
          {
            const HyperedgeWeight gain_after = gainOfHyperedge(
                source, target, edge_weight, target_graph, pin_counts, connectivity_set);
            _gain_cache[benefit_index(pin, target)].add_fetch(gain_after,
                                                              std::memory_order_relaxed);
          }
        }
      }

      // Reconstruct connectivity set and pin counts before the node move
      reconstructConnectivitySetAndPinCountsBeforeMove(sync_update, connectivity_set,
                                                       pin_counts);
      // Compute old gain of hyperedge for all pins and their adjacent blocks and
      // subtract it from the gain cache entries
      for(const HypernodeID &pin : partitioned_hg.pins(he))
      {
        const PartitionID source = partitioned_hg.partID(pin);
        for(const PartitionID &target : _adjacent_blocks.connectivitySet(pin))
        {
          if(source != target)
          {
            const HyperedgeWeight gain_before = gainOfHyperedge(
                source, target, edge_weight, target_graph, pin_counts, connectivity_set);
            _gain_cache[benefit_index(pin, target)].sub_fetch(gain_before,
                                                              std::memory_order_relaxed);
          }
        }
      }
    }
    else
    {
      if(pin_count_in_from_part_after == 1)
      {
        // In this case, there is only one pin left in block `from` and moving it to
        // another block would remove the block from the connectivity set. Thus, we search
        // for the last remaining pin in that block and update its gains for moving it to
        // all its adjacent blocks.
        for(const HypernodeID &u : partitioned_hg.pins(he))
        {
          if(partitioned_hg.partID(u) == from)
          {
            for(const PartitionID &target : _adjacent_blocks.connectivitySet(u))
            {
              if(from != target)
              {
                // Compute new gain of hyperedge for moving u to the target block
                const HyperedgeWeight gain =
                    gainOfHyperedge(from, target, edge_weight, target_graph, pin_counts,
                                    connectivity_set);
                _gain_cache[benefit_index(u, target)].add_fetch(
                    gain, std::memory_order_relaxed);

                // Before the node move, we would have increase the connectivity of the
                // hyperedge if we would have moved u to a block not in the connectivity
                // set of the hyperedge. Thus, we subtract the old gain from gain cache
                // entry.
                const HypernodeID pin_count_target_part_before =
                    target == to ? pin_count_in_to_part_after - 1 :
                                   pin_counts.pinCountInPart(target);
                if(pin_count_target_part_before == 0)
                {
                  // The target part was not part of the connectivity set of the hyperedge
                  // before the move. Thus, moving u to that block would have increased
                  // the connectivity of the hyperedge. However, this is no longer the
                  // case since moving u out of its block would remove the block from the
                  // connectivity set.
                  const bool was_set = connectivity_set.isSet(target);
                  connectivity_set.unset(target);
                  const HyperedgeWeight distance_before =
                      target_graph.distance(connectivity_set);
                  const HyperedgeWeight distance_after =
                      target_graph.distanceWithBlock(connectivity_set, target);
                  const HyperedgeWeight gain_before =
                      (distance_before - distance_after) * edge_weight;
                  _gain_cache[benefit_index(u, target)].sub_fetch(
                      gain_before, std::memory_order_relaxed);
                  if(was_set)
                    connectivity_set.set(target);
                }
              }
            }
          }
        }
      }

      if(pin_count_in_to_part_after == 2)
      {
        // In this case, there are now two pins in block `to`. However, moving out the
        // previously last pin of block `to` would have decreased the connectivity of the
        // hyperedge. This is no longer the case since there are two pins in the block.
        // Thus, we search for this pin and update its gain.
        for(const HypernodeID &u : partitioned_hg.pins(he))
        {
          if(partitioned_hg.partID(u) == to)
          {
            for(const PartitionID &target : _adjacent_blocks.connectivitySet(u))
            {
              if(target != to)
              {
                // Compute new gain of hyperedge for moving u to the target block
                const HyperedgeWeight gain = gainOfHyperedge(
                    to, target, edge_weight, target_graph, pin_counts, connectivity_set);
                _gain_cache[benefit_index(u, target)].add_fetch(
                    gain, std::memory_order_relaxed);

                // Before the node move, we would have decreased the connectivity of the
                // hyperedge if we would have moved u to a block in the connecivity set or
                // replaced its block with another if we would have moved it to block not
                // in the connectivity set. Thus, we subtract the old gain from gain cache
                // entry.
                const HypernodeID pin_count_target_part_before =
                    target == from ? pin_count_in_from_part_after + 1 :
                                     pin_counts.pinCountInPart(target);
                const bool was_set = connectivity_set.isSet(target);
                if(pin_count_target_part_before == 0)
                  connectivity_set.unset(target);
                const HyperedgeWeight distance_before =
                    target_graph.distance(connectivity_set);
                HyperedgeWeight distance_after = 0;
                if(pin_count_target_part_before > 0)
                {
                  // The target block was part of the connectivity set before the node
                  // move. Thus, moving u out of its block would have decreased the
                  // connectivity of the hyperedge.
                  distance_after =
                      target_graph.distanceWithoutBlock(connectivity_set, to);
                }
                else
                {
                  // The target block was not part of the connectivity set before the node
                  // move. Thus, moving u out of its block would have replaced block `to`
                  // with the target block in the connectivity set.
                  distance_after = target_graph.distanceAfterExchangingBlocks(
                      connectivity_set, to, target);
                }
                const HyperedgeWeight gain_before =
                    (distance_before - distance_after) * edge_weight;
                _gain_cache[benefit_index(u, target)].sub_fetch(
                    gain_before, std::memory_order_relaxed);
                if(was_set)
                  connectivity_set.set(target);
              }
            }
          }
        }
      }
    }

    // Update gain version of hyperedge. If the update version is equal to the version
    // of the hyperedge, then we know that all gain cache updates are completed. This is
    // important for initializing gain entries while simultanously running gain cache
    // updates.
    ++_version[sync_update.he].update_version;
  }

  // We update the adjacent blocks of nodes affected by this gain cache update
  // which will then trigger initialization of gain entries if a node becomes adjacent
  // to a new block.
  updateAdjacentBlocks(partitioned_hg, sync_update);
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::uncontractUpdateAfterRestore(
    const PartitionedHypergraph &partitioned_hg, const HypernodeID u, const HypernodeID v,
    const HyperedgeID he, const HypernodeID pin_count_in_part_after)
{
  // In this case, u and v are both contained in the hyperedge after the uncontraction
  // operation
  // => Pin count of the block of node u increases by one, but connectivity set does not
  // change.
  if(_is_initialized)
  {
    ASSERT(partitioned_hg.hasTargetGraph());
    const TargetGraph &target_graph = *partitioned_hg.targetGraph();
    const PartitionID block = partitioned_hg.partID(u);
    const HyperedgeWeight edge_weight = partitioned_hg.edgeWeight(he);
    if(pin_count_in_part_after == 2)
    {
      // In this case, u was the only pin of its block contained in the hyperedge.
      // Aftwards, u and v are contained in the hyperedge both in the same block.
      // This changes the gain of u to all its adjacent blocks
      for(const HypernodeID &pin : partitioned_hg.pins(he))
      {
        // u might be replaced by an other node in the batch
        // => search for other pin of the corresponding block and update gain.
        if(pin != v && partitioned_hg.partID(pin) == block)
        {
          ds::Bitset &connectivity_set = partitioned_hg.deepCopyOfConnectivitySet(he);
          const HyperedgeWeight current_distance =
              target_graph.distance(connectivity_set);
          for(const PartitionID to : _adjacent_blocks.connectivitySet(pin))
          {
            if(block != to)
            {
              // u does no longer decrease the connectivity of the hyperedge. We therefore
              // subtract the previous contribution of the hyperedge to gain values of u
              HyperedgeWeight old_distance_after_move = 0;
              HyperedgeWeight new_distance_after_move = current_distance;
              if(partitioned_hg.pinCountInPart(he, to) == 0)
              {
                old_distance_after_move = target_graph.distanceAfterExchangingBlocks(
                    connectivity_set, block, to);
                new_distance_after_move =
                    target_graph.distanceWithBlock(connectivity_set, to);
              }
              else
              {
                old_distance_after_move =
                    target_graph.distanceWithoutBlock(connectivity_set, block);
              }
              const HyperedgeWeight old_gain =
                  (current_distance - old_distance_after_move) * edge_weight;
              const HyperedgeWeight new_gain =
                  (current_distance - new_distance_after_move) * edge_weight;
              _gain_cache[benefit_index(pin, to)].add_fetch(new_gain - old_gain,
                                                            std::memory_order_relaxed);
            }
          }
          break;
        }
      }
    }

    if(partitioned_hg.edgeSize(he) > _large_he_threshold)
    {
      for(const HypernodeID &pin : partitioned_hg.pins(he))
      {
        for(const PartitionID &block : partitioned_hg.connectivitySet(he))
        {
          decrementIncidentEdges(pin, block);
        }
      }
    }

    // Other gain cache implementations initialize here the gain of node v.
    // However, this not possible since there are still pending uncontractions and
    // we do not know all adjacent blocks of node v at this point. We therefore initialize
    // them after all uncontractions are finished.
  }
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::uncontractUpdateAfterReplacement(
    const PartitionedHypergraph &partitioned_hg, const HypernodeID u, const HypernodeID,
    const HyperedgeID he)
{
  // In this case, u is replaced by v in hyperedge he
  // => Pin counts and connectivity set of hyperedge he does not change
  if(_is_initialized)
  {
    ASSERT(partitioned_hg.hasTargetGraph());
    const TargetGraph &target_graph = *partitioned_hg.targetGraph();
    const PartitionID block = partitioned_hg.partID(u);
    const HyperedgeWeight edge_weight = partitioned_hg.edgeWeight(he);
    ds::Bitset &connectivity_set = partitioned_hg.deepCopyOfConnectivitySet(he);
    const HyperedgeWeight current_distance = target_graph.distance(connectivity_set);
    // Since u is no longer part of the hyperedge, we have to subtract the previous
    // contribution of the hyperedge for moving u out of its block from all its gain
    // values and add its new contribution.
    if(partitioned_hg.pinCountInPart(he, block) == 1)
    {
      for(const PartitionID to : _adjacent_blocks.connectivitySet(u))
      {
        if(block != to)
        {
          HyperedgeWeight distance_used_for_gain = 0;
          if(partitioned_hg.pinCountInPart(he, to) == 0)
          {
            distance_used_for_gain =
                target_graph.distanceAfterExchangingBlocks(connectivity_set, block, to);
          }
          else
          {
            distance_used_for_gain =
                target_graph.distanceWithoutBlock(connectivity_set, block);
          }
          const HyperedgeWeight old_gain =
              (current_distance - distance_used_for_gain) * edge_weight;
          _gain_cache[benefit_index(u, to)].sub_fetch(old_gain,
                                                      std::memory_order_relaxed);
        }
      }
    }
    else
    {
      for(const PartitionID to : _adjacent_blocks.connectivitySet(u))
      {
        if(block != to && partitioned_hg.pinCountInPart(he, to) == 0)
        {
          const HyperedgeWeight distance_with_to =
              target_graph.distanceWithBlock(connectivity_set, to);
          const HyperedgeWeight old_gain =
              (current_distance - distance_with_to) * edge_weight;
          _gain_cache[benefit_index(u, to)].sub_fetch(old_gain,
                                                      std::memory_order_relaxed);
        }
      }
    }

    // Decrement number of incident edges of each block in the connectivity set
    // of the hyperedge since u is no longer part of the hyperedge.
    if(partitioned_hg.edgeSize(he) <= _large_he_threshold)
    {
      for(const PartitionID &to : partitioned_hg.connectivitySet(he))
      {
        decrementIncidentEdges(u, to);
      }
    }

    // Other gain cache implementations initialize here the gain of node v.
    // However, this not possible since there are still pending uncontractions and
    // we do not know all adjacent blocks of node v at this point. We therefore initialize
    // them after all uncontractions are finished.
  }
}

void SteinerTreeGainCache::restoreSinglePinHyperedge(const HypernodeID u,
                                                     const PartitionID block_of_u,
                                                     const HyperedgeWeight)
{
  incrementIncidentEdges(u, block_of_u);
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::restoreIdenticalHyperedge(
    const PartitionedHypergraph &partitioned_hg, const HyperedgeID he)
{
  if(partitioned_hg.edgeSize(he) <= _large_he_threshold)
  {
    for(const HypernodeID &pin : partitioned_hg.pins(he))
    {
      for(const PartitionID &block : partitioned_hg.connectivitySet(he))
      {
        incrementIncidentEdges(pin, block);
      }
    }
  }
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::initializeAdjacentBlocks(
    const PartitionedHypergraph &partitioned_hg)
{
  // Initialize adjacent blocks of each node
  partitioned_hg.doParallelForAllNodes(
      [&](const HypernodeID &hn) { initializeAdjacentBlocksOfNode(partitioned_hg, hn); });
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::initializeAdjacentBlocksOfNode(
    const PartitionedHypergraph &partitioned_hg, const HypernodeID hn)
{
  _adjacent_blocks.clear(hn);
  for(PartitionID to = 0; to < _k; ++to)
  {
    _num_incident_edges_of_block[benefit_index(hn, to)].store(0,
                                                              std::memory_order_relaxed);
  }
  for(const HyperedgeID &he : partitioned_hg.incidentEdges(hn))
  {
    if(partitioned_hg.edgeSize(he) <= _large_he_threshold)
    {
      for(const PartitionID &block : partitioned_hg.connectivitySet(he))
      {
        incrementIncidentEdges(hn, block);
      }
    }
  }
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::updateAdjacentBlocks(
    const PartitionedHypergraph &partitioned_hg,
    const SynchronizedEdgeUpdate &sync_update)
{
  if(partitioned_hg.edgeSize(sync_update.he) <= _large_he_threshold)
  {
    if(sync_update.pin_count_in_from_part_after == 0)
    {
      // The node move has removed the source block of the move from the
      // connectivity set of the hyperedge. We therefore decrement the number of
      // incident edges in the source block for each pin of the hyperedge. If this
      // decreases the counter to zero for some pin, we remove the source block
      // from the adjacent blocks of that pin.
      for(const HypernodeID &pin : partitioned_hg.pins(sync_update.he))
      {
        decrementIncidentEdges(pin, sync_update.from);
      }
    }
    if(sync_update.pin_count_in_to_part_after == 1)
    {
      // The node move has added the target block of the move to the
      // connectivity set of the hyperedge. We therefore increment the number of
      // incident edges in the target block for each pin of the hyperedge. If this
      // increases the counter to one for some pin, we add the target block
      // to the adjacent blocks of that pin. Moreover, since we only compute gain
      // cache entries to adjacent blocks, we initialize the gain cache entry
      // for that pin and target block.
      for(const HypernodeID &pin : partitioned_hg.pins(sync_update.he))
      {
        const HyperedgeID incident_edges_after =
            incrementIncidentEdges(pin, sync_update.to);
        if(incident_edges_after == 1)
        {
          ASSERT(sync_update.edge_locks);
          initializeGainCacheEntry(partitioned_hg, pin, sync_update.to,
                                   *sync_update.edge_locks);
        }
      }
    }
  }
}

HyperedgeID SteinerTreeGainCache::incrementIncidentEdges(const HypernodeID u,
                                                         const PartitionID to)
{
  const HyperedgeID incident_count_after =
      _num_incident_edges_of_block[benefit_index(u, to)].add_fetch(
          1, std::memory_order_relaxed);
  if(incident_count_after == 1)
  {
    ASSERT(!_adjacent_blocks.contains(u, to));
    _gain_cache[benefit_index(u, to)].store(0, std::memory_order_relaxed);
    _adjacent_blocks.add(u, to);
  }
  return incident_count_after;
}

HyperedgeID SteinerTreeGainCache::decrementIncidentEdges(const HypernodeID u,
                                                         const PartitionID to)
{
  ASSERT(_num_incident_edges_of_block[benefit_index(u, to)].load() > 0);
  const HyperedgeID incident_count_after =
      _num_incident_edges_of_block[benefit_index(u, to)].sub_fetch(
          1, std::memory_order_relaxed);
  if(incident_count_after == 0)
  {
    ASSERT(_adjacent_blocks.contains(u, to));
    _adjacent_blocks.remove(u, to);
  }
  return incident_count_after;
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::initializeGainCacheEntryForNode(
    const PartitionedHypergraph &partitioned_hg, const HypernodeID u,
    vec<Gain> &benefit_aggregator)
{
  ASSERT(partitioned_hg.hasTargetGraph());
  const TargetGraph &target_graph = *partitioned_hg.targetGraph();
  const PartitionID from = partitioned_hg.partID(u);

  // We only compute the gain to adjacent blocks of a node and initialize them here.
  // The gain to non-adjacent blocks is -inf.
  for(const PartitionID &to : _adjacent_blocks.connectivitySet(u))
  {
    benefit_aggregator[to] = 0;
  }

  for(const HyperedgeID &he : partitioned_hg.incidentEdges(u))
  {
    const HyperedgeWeight edge_weight = partitioned_hg.edgeWeight(he);
    ds::Bitset &connectivity_set = partitioned_hg.deepCopyOfConnectivitySet(he);

    const HyperedgeWeight current_distance = target_graph.distance(connectivity_set);
    if(partitioned_hg.pinCountInPart(he, from) == 1)
    {
      // Moving the node out of its current block removes
      // its block from the connectivity set
      connectivity_set.unset(from);
    }
    // Compute gain to all adjacent blocks
    for(const PartitionID &to : _adjacent_blocks.connectivitySet(u))
    {
      const HyperedgeWeight distance_with_to =
          target_graph.distanceWithBlock(connectivity_set, to);
      benefit_aggregator[to] += (current_distance - distance_with_to) * edge_weight;
    }
  }

  for(PartitionID to = 0; to < _k; ++to)
  {
    _gain_cache[benefit_index(u, to)].store(benefit_aggregator[to],
                                            std::memory_order_relaxed);
    benefit_aggregator[to] = std::numeric_limits<Gain>::min();
  }
}

template <typename PartitionedHypergraph>
void SteinerTreeGainCache::initializeGainCacheEntry(
    const PartitionedHypergraph &partitioned_hg, const HypernodeID hn,
    const PartitionID to, ds::Array<SpinLock> &edge_locks)
{
  ASSERT(partitioned_hg.hasTargetGraph());
  const TargetGraph &target_graph = *partitioned_hg.targetGraph();
  const HypernodeID from = partitioned_hg.partID(hn);
  vec<uint32_t> &seen_versions = _ets_version.local();
  bool success = false;
  while(!success)
  {
    success = true;
    seen_versions.clear();
    HyperedgeWeight gain = 0;
    for(const HyperedgeID &he : partitioned_hg.incidentEdges(hn))
    {
      edge_locks[partitioned_hg.uniqueEdgeID(he)].lock();
      // The internal data structures in the partitioned hypergraph are updated
      // in one transaction and each update is assoicated with a version ID. We
      // retrieve here the actual state of the connectivity set of the hyperedge
      // with its version ID. If this version ID changes after the gain computation,
      // we know that we computed the gain on outdated information and retry.
      const uint32_t update_version =
          _version[he].update_version.load(std::memory_order_relaxed);
      const uint32_t he_version = _version[he].version.load(std::memory_order_relaxed);
      ds::Bitset &connectivity_set = partitioned_hg.deepCopyOfConnectivitySet(he);
      edge_locks[partitioned_hg.uniqueEdgeID(he)].unlock();

      ASSERT(update_version <= he_version);
      if(update_version < he_version)
      {
        // There are still pending gain cache updates that must be finished
        // before we initialize the gain cache entry.
        success = false;
        break;
      }
      seen_versions.push_back(he_version);

      // Now compute gain of moving node hn to block `to` for hyperedge
      const HyperedgeWeight current_distance = target_graph.distance(connectivity_set);
      if(partitioned_hg.pinCountInPart(he, from) == 1)
      {
        // Moving the node out of its current block removes
        // its block from the connectivity set
        connectivity_set.unset(from);
      }
      const HyperedgeWeight distance_with_to =
          target_graph.distanceWithBlock(connectivity_set, to);
      gain += (current_distance - distance_with_to) * partitioned_hg.edgeWeight(he);
    }
    _gain_cache[benefit_index(hn, to)].store(gain, std::memory_order_relaxed);

    // Check if versions of an incident hyperedge has changed in the meantime.
    // If not, gain cache entry is correct. Otherwise, recompute it.
    if(success)
    {
      ASSERT(seen_versions.size() == UL(partitioned_hg.nodeDegree(hn)),
             V(hn) << V(seen_versions.size()) << V(partitioned_hg.nodeDegree(hn)));
      size_t idx = 0;
      for(const HyperedgeID &he : partitioned_hg.incidentEdges(hn))
      {
        if(seen_versions[idx++] != _version[he].version.load(std::memory_order_relaxed))
        {
          success = false;
          break;
        }
      }
    }
  }
}

template <typename PartitionedHypergraph>
bool SteinerTreeGainCache::verifyTrackedAdjacentBlocksOfNodes(
    const PartitionedHypergraph &partitioned_hg) const
{
  bool success = true;
  vec<HyperedgeID> num_incident_edges(_k, 0);
  for(const HypernodeID &hn : partitioned_hg.nodes())
  {
    num_incident_edges.assign(_k, 0);
    for(const HyperedgeID &he : partitioned_hg.incidentEdges(hn))
    {
      if(partitioned_hg.edgeSize(he) <= _large_he_threshold)
      {
        for(const PartitionID &block : partitioned_hg.connectivitySet(he))
        {
          ++num_incident_edges[block];
        }
      }
    }

    for(PartitionID block = 0; block < _k; ++block)
    {
      if(_num_incident_edges_of_block[benefit_index(hn, block)] !=
         num_incident_edges[block])
      {
        LOG << "Number of incident edges of node" << hn << "to block" << block << "=>"
            << "Expected:" << num_incident_edges[block] << ","
            << "Actual:" << _num_incident_edges_of_block[benefit_index(hn, block)];
        success = false;
      }
    }

    for(const PartitionID block : _adjacent_blocks.connectivitySet(hn))
    {
      if(num_incident_edges[block] == 0)
      {
        LOG << "Node" << hn << "is not adjacent to block" << block
            << ", but it is in its connectivity set";
        success = false;
      }
    }

    for(PartitionID block = 0; block < _k; ++block)
    {
      if(num_incident_edges[block] > 0 && !_adjacent_blocks.contains(hn, block))
      {
        LOG << "Node" << hn << "should be adjacent to block" << block
            << ", but it is not in its connectivity set";
        success = false;
      }
    }
  }
  return success;
}

namespace {
#define STEINER_TREE_INITIALIZE_GAIN_CACHE(X)                                            \
  void SteinerTreeGainCache::initializeGainCache(const X &)
#define STEINER_TREE_INITIALIZE_GAIN_CACHE_FOR_NODE(X)                                   \
  void SteinerTreeGainCache::initializeGainCacheEntryForNode(const X &, const HypernodeID)
#define STEINER_TREE_NOTIFY(X)                                                           \
  void SteinerTreeGainCache::notifyBeforeDeltaGainUpdate(const X &,                      \
                                                         const SynchronizedEdgeUpdate &)
#define STEINER_TREE_DELTA_GAIN_UPDATE(X)                                                \
  void SteinerTreeGainCache::deltaGainUpdate(const X &, const SynchronizedEdgeUpdate &)
#define STEINER_TREE_RESTORE_UPDATE(X)                                                   \
  void SteinerTreeGainCache::uncontractUpdateAfterRestore(                               \
      const X &, const HypernodeID, const HypernodeID, const HyperedgeID,                \
      const HypernodeID)
#define STEINER_TREE_REPLACEMENT_UPDATE(X)                                               \
  void SteinerTreeGainCache::uncontractUpdateAfterReplacement(                           \
      const X &, const HypernodeID, const HypernodeID, const HyperedgeID)
#define STEINER_TREE_RESTORE_IDENTICAL_HYPEREDGE(X)                                      \
  void SteinerTreeGainCache::restoreIdenticalHyperedge(const X &, const HyperedgeID)
#define STEINER_TREE_INIT_ADJACENT_BLOCKS(X)                                             \
  void SteinerTreeGainCache::initializeAdjacentBlocks(const X &)
#define STEINER_TREE_INIT_ADJACENT_BLOCKS_OF_NODE(X)                                     \
  void SteinerTreeGainCache::initializeAdjacentBlocksOfNode(const X &, const HypernodeID)
#define STEINER_TREE_UPDATE_ADJACENT_BLOCKS(X)                                           \
  void SteinerTreeGainCache::updateAdjacentBlocks(const X &,                             \
                                                  const SynchronizedEdgeUpdate &)
#define STEINER_TREE_INIT_GAIN_CACHE_ENTRY(X)                                            \
  void SteinerTreeGainCache::initializeGainCacheEntryForNode(                            \
      const X &, const HypernodeID, vec<Gain> &)
#define STEINER_TREE_INIT_LAZY_GAIN_CACHE_ENTRY(X)                                       \
  void SteinerTreeGainCache::initializeGainCacheEntry(                                   \
      const X &, const HypernodeID, const PartitionID, ds::Array<SpinLock> &)
#define STEINER_TREE_VERIFY_ADJACENT_BLOCKS(X)                                           \
  bool SteinerTreeGainCache::verifyTrackedAdjacentBlocksOfNodes(const X &) const
}

INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_INITIALIZE_GAIN_CACHE)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_INITIALIZE_GAIN_CACHE_FOR_NODE)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_NOTIFY)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_DELTA_GAIN_UPDATE)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_RESTORE_UPDATE)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_REPLACEMENT_UPDATE)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_RESTORE_IDENTICAL_HYPEREDGE)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_INIT_ADJACENT_BLOCKS)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_INIT_ADJACENT_BLOCKS_OF_NODE)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_UPDATE_ADJACENT_BLOCKS)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_INIT_GAIN_CACHE_ENTRY)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_INIT_LAZY_GAIN_CACHE_ENTRY)
INSTANTIATE_FUNC_WITH_PARTITIONED_HG(STEINER_TREE_VERIFY_ADJACENT_BLOCKS)

} // namespace mt_kahypar
